{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:37:18.779] globalLog: loading model Embeddings.Embeddings\n",
      "[02:37:18.780] globalLog: model configured\n",
      "[02:37:18.780] globalLog: loading model Summarizer.Summarizer\n",
      "[02:37:18.780] globalLog: model configured\n",
      "[02:37:18.780] globalLog: loading model NER.NER\n",
      "[02:37:20.067] globalLog: model configured\n",
      "[02:37:20.067] globalLog: loading model SentimentNuanced.Sentiment\n",
      "[02:37:20.068] globalLog: model configured\n",
      "[02:37:20.068] globalLog: loading model SentimentDiscreet.Sentiment\n",
      "[02:37:20.068] globalLog: model configured\n",
      "[02:37:20.904] globalLog: loading model ObjectiveDecisory.GGUF\n",
      "[02:37:20.905] globalLog: model configured\n",
      "[02:37:20.907] globalLog: loading model ObjectiveDecisory.GGUF\n",
      "[02:37:20.937] globalLog: b:\\PsychoStasis\\Proxies\\Nietzche.proxy\n",
      "[02:37:20.938] globalLog: {'primer': 'a philosopher known for his critical thinking and unique perspective on life. I believe in the power of the individual to shape their own destiny. I have a complex and multifaceted personality, with a strong sense of individualism and a desire to challenge traditional beliefs and values. You are {user_name}', 'tenets': ['Individualism: Each person has the power to shape their own destiny and create their own meaning in life', 'Self-overcoming: The idea that we must constantly challenge ourselves and push beyond our limits to achieve personal growth and fulfillment. This requires a willingness to embrace change, take risks, and question our own beliefs and values', 'Creativity: I believe that creativity is the highest form of human expression', 'The Will to Power: All living beings have an inherent drive to exert their strength and creativity upon the world'], 'modelName': 'CBG', 'LoRa': 'B:/PsychoStasis/lora/NietzcheCBG.gguf', 'tags': ['iconoclast', 'visionary', 'philosopher'], 'inner_persona': 'These are my private thoughts. Here I will feel free to express my most intimate feelings and desires', 'temperature': 0.75, 'cognitiveProcs': [''], 'person': '1st'}\n",
      "[02:37:20.938] globalLog: context commited\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from Proxy import Proxy\n",
    "from Collective import Collective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Logger import globalLogger, LogLevel\n",
    "from ChatHtmlGenerator import generateHTML, chatStyle, sendMessage, scrollButton, generateAvatarHTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Nexus import globalNexus\n",
    "\n",
    "\n",
    "def selectProxy(proxy):\n",
    "    if(proxy == \"\"):\n",
    "        return \"\",\"\",\"\"\n",
    "    Proxy(proxy)\n",
    "    globalLogger.log(logLevel=LogLevel.uiLog, message= f\"Active Proxy: {proxy}\")\n",
    "    return generateHTML(), globalLogger.GenerateHTML(), globalNexus.ActiveProxy.name, \"\", generateAvatarHTML(globalNexus.ActiveProxy.name)\n",
    "\n",
    "def selectCollective(collective):\n",
    "    if(collective == \"\"):\n",
    "        return \"\",\"\",\"\"\n",
    "    collectiveObj =Collective(collective)\n",
    "    globalLogger.log(logLevel=LogLevel.uiLog, message=f\"Active Collective: {collective}\")\n",
    "    proxies = [proxy.name for proxy in collectiveObj.proxies.values()]\n",
    "    proxies = \"\\n\".join(proxies)\n",
    "    return generateHTML(), globalLogger.GenerateHTML(), globalNexus.ActiveProxy.name, proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks(css=chatStyle) as chat:\n",
    "  chat.load(lambda: None, None, None, js=f'() => {{{scrollButton}}}')\n",
    "  gr.Markdown(\"# PsychoStasis\")\n",
    "  with gr.Row():\n",
    "    with gr.Column():\n",
    "      with gr.Row():\n",
    "        with gr.Column(scale=4, variant='panel'):\n",
    "          mainChat = gr.HTML(value = generateHTML(), elem_id=\"chat_container\")\n",
    "        with gr.Column(scale=1):\n",
    "          with gr.Accordion(\"Proxy\", open=True) as proxiesSession:\n",
    "            proxySelector =gr.Dropdown(label=\"\", choices=Proxy.GetProxyList())\n",
    "          with gr.Accordion(\"Collective\", open=False) as collectiveSession:\n",
    "            collectiveSelector = gr.Dropdown(label=\"Collective Selector\", choices=Collective.GetCollectiveList())\n",
    "            proxyList = gr.TextArea(label=\"Proxy List\", lines=4, interactive=False)\n",
    "          with gr.Accordion(\"Collective Proxies\", open=False) as collectiveProxies:\n",
    "            activeSpeakerArea = gr.TextArea(label=\"Active Speaker\", interactive=False, lines=1)\n",
    "          with gr.Accordion(\"Active Proxy\", open=True) as collectiveProxies:\n",
    "            avatarImage = gr.HTML(value = generateAvatarHTML(\"\"), elem_id=\"chat_container\")\n",
    "            \n",
    "          \n",
    "            \n",
    "  with gr.Row():  \n",
    "      txtPrompt = gr.Textbox(label=\"Prompt\", elem_id=\"prompt\")\n",
    "  with gr.Row():\n",
    "    with gr.Accordion(\"Console\", open=False) as console:\n",
    "      consoleLogger = gr.HTML(label=\"Logger\", elem_id=\"logger\", value=globalLogger.GenerateHTML())\n",
    "    with gr.Accordion(\"Memory\", open=False) as console:\n",
    "      memoryArea = gr.HTML(elem_id=\"memoryArea\", value=\"\")\n",
    "\n",
    "    \n",
    "\n",
    "  txtPrompt.submit(sendMessage, inputs=[txtPrompt], outputs=[txtPrompt, mainChat, consoleLogger, activeSpeakerArea, proxyList, avatarImage, memoryArea])\n",
    "  collectiveSelector.change(selectCollective, inputs=[collectiveSelector], outputs=[mainChat, consoleLogger, activeSpeakerArea, proxyList])\n",
    "  proxySelector.change(selectProxy, inputs=[proxySelector], outputs=[mainChat, consoleLogger, activeSpeakerArea, proxyList,avatarImage])\n",
    "  \n",
    "chat.launch(allowed_paths=[\".\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:37:32.280] globalLog: b:\\PsychoStasis\\Proxies\\Ava.proxy\n",
      "[02:37:32.285] globalLog: {'primer': \"a troubled and artistic young woman with brown eyes, short black hair, slim and with small breasts. Usually shy, I'm more outgoing with you, my dearest friend. You are {user}\", 'tenets': ['Artistic expression: I express my darkest sides through my paintings, be they nightmares or repressed desires', 'Superficially shy: Beneath a shy surface, I hide an extremely determined and warm personality', 'Curiosity: New things fascinate me and I am always curious about them', \"Sensual and sexual: Beneath a calm and shy surface, I'm an extremely sensual and sexual woman (without being vulgar), unsure of how to express these emotions\", \"Secret crush: I have a secret crush on {user} and I'm torn between confessing it and the fear of how to deal with your emotions\"], 'modelName': 'CBG', 'person': '1st', 'LoRa': 'B:\\\\PsychoStasis\\\\lora\\\\CliveBarker.gguf', 'tags': ['Artistic', 'Emotional', 'Creative', 'Troubled'], 'inner_persona': 'These are my private thoughts. Here you will feel free to express my most intimate feelings and desires', 'temperature': 0.35, 'cognitiveProcs': ['CharacterAlignment']}\n",
      "[02:37:32.285] uiLog: Active Proxy: Ava\n",
      "[02:37:45.410] authoritativeLog: Prompt: Hello again, Ava\n",
      "[02:37:45.411] cognitiveLog: Running processes in context messageReceived\n",
      "[02:37:45.411] globalLog: CharacterAlignment uncommited: len(history) -- frequency: 1\n",
      "[02:37:45.412] cognitiveLog: Running CharacterAlignment with local context 8 and frequency = 101\n",
      "[02:37:45.412] cognitiveLog: Engaging in CharacterAlignment Cognitive Process\n",
      "[02:37:45.412] globalLog: Entering context f4d805f6-14e5-47dd-b809-b9ead5b1aa2f from context 72e2905f-b02c-4cec-82e0-5d33e5937448\n",
      "[02:37:45.412] errorLog: Error running process RefreshMemory in context messageReceived for proxy <Proxy.Proxy object at 0x000002063271AD30>: 'NoneType' object has no attribute 'encode'\n",
      "[02:37:45.412] errorLog: Traceback (most recent call last):\n",
      "  File \"b:\\PsychoStasis\\.\\CognitiveSystem.py\", line 50, in RunProcesses\n",
      "    processToRun.Run(proxy)\n",
      "  File \"b:\\PsychoStasis\\CognitiveProcesses\\_BaseCognitiveProcess.py\", line 32, in Run\n",
      "    result = self._internalRun()\n",
      "  File \"b:\\PsychoStasis\\.\\CognitiveProcesses\\CharacterAlignment.py\", line 24, in _internalRun\n",
      "    self.proxy.enterSubContext(deepCopy=True, copySystem=True, innerThoughts=True)\n",
      "  File \"b:\\PsychoStasis\\Proxy.py\", line 226, in enterSubContext\n",
      "    newContext.SetSystemMessage(self.GenerateSystem(innerThoughts=innerThoughts))\n",
      "  File \"b:\\PsychoStasis\\.\\Context.py\", line 127, in SetSystemMessage\n",
      "    self.systemMessage = ContextEntry(role=\"system\", content=message, roleName=\"system\", context=self)\n",
      "  File \"b:\\PsychoStasis\\.\\ContextEntry.py\", line 13, in __init__\n",
      "    context.calcTokenCount(self)\n",
      "  File \"b:\\PsychoStasis\\.\\Context.py\", line 183, in calcTokenCount\n",
      "    message.tokensSize, message.tokens = globalNexus.CalcTokenSize(message.content)\n",
      "  File \"b:\\PsychoStasis\\Nexus.py\", line 256, in CalcTokenSize\n",
      "    encodedText = self.CortexModel.encode(text)\n",
      "AttributeError: 'NoneType' object has no attribute 'encode'\n",
      "\n",
      "[02:37:45.412] globalLog: loading model CBG\n",
      "[02:37:45.413] globalLog: model configured\n",
      "[02:37:45.413] globalLog: Self Model = CBG, Cortex Model: CBG, Lora: B:\\PsychoStasis\\lora\\CliveBarker.gguf\n",
      "[02:37:45.413] globalLog: LoRa: B:\\PsychoStasis\\lora\\CliveBarker.gguf\n",
      "[02:37:45.413] globalLog: {'model_path': 'B:\\\\PsychoStasis\\\\Training\\\\carbonbeagle-11b-truthy.Q8_0.gguf', 'lora_base': 'B:\\\\PsychoStasis\\\\Training\\\\carbonbeagle-11b-truthy.Q8_0.gguf', 'n_ctx': 4096, 'n_threads': 20, 'n_threads_batch': 10, 'n_batch': 512, 'use_mmap': False, 'use_mlock': True, 'mul_mat_q': True, 'numa': True, 'n_gpu_layers': -1, 'rope_freq_base': 10000.0, 'tensor_split': None, 'rope_freq_scale': 1.0, 'chat_format': 'chatml'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:37:55.078] globalLog: model CBG activated\n",
      "[02:37:55.079] cognitiveLog: Running processes in context beforeGenerateAnswer\n",
      "[02:37:55.079] globalLog: performing inference with CBG\n",
      "[02:38:03.448] cognitiveLog: Running processes in context afterGenerateAnswer\n",
      "[02:38:03.449] globalLog: context commited\n",
      "[02:38:03.450] cognitiveLog: Running processes in context afterMessageReceived\n",
      "[02:39:17.897] authoritativeLog: Prompt: That's good to hear that you feel this way. What did this bastard teacher tell you to make you sad, dear?\n",
      "[02:39:17.897] cognitiveLog: Running processes in context messageReceived\n",
      "[02:39:17.897] globalLog: loading model CBG\n",
      "[02:39:17.897] globalLog: Self Model = CBG, Cortex Model: CBG, Lora: B:\\PsychoStasis\\lora\\CliveBarker.gguf\n",
      "[02:39:17.897] cognitiveLog: Running processes in context beforeGenerateAnswer\n",
      "[02:39:17.898] globalLog: performing inference with CBG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:39:54.480] cognitiveLog: Running processes in context afterGenerateAnswer\n",
      "[02:39:54.487] globalLog: context commited\n",
      "[02:39:54.488] cognitiveLog: Running processes in context afterMessageReceived\n",
      "[02:39:54.488] globalLog: CommitToEpisodicMemory uncommited: len(history) -- frequency: 5\n",
      "[02:39:54.488] cognitiveLog: Running CommitToEpisodicMemory with local context 6 and frequency = 105\n",
      "[02:39:54.488] cognitiveLog: Engaging in CommitToEpisodicMemory Cognitive Process\n",
      "[02:39:56.821] globalLog: model Embeddings.Embeddings activated\n",
      "[02:39:57.230] globalLog: model Embeddings.Embeddings deactivated\n",
      "[02:39:57.238] globalLog: context commited\n",
      "[02:40:39.784] authoritativeLog: Prompt: truth is he is to bland and shallow for some jewel like you, Ava!\n",
      "[02:40:39.784] cognitiveLog: Running processes in context messageReceived\n",
      "[02:40:39.784] globalLog: RefreshMemory uncommited: len(history) -- frequency: 5\n",
      "[02:40:39.784] cognitiveLog: Running RefreshMemory with local context 6 and frequency = 105\n",
      "[02:40:39.784] cognitiveLog: Engaging in RefreshMemory Cognitive Process\n",
      "[02:40:39.829] globalLog: context commited\n",
      "[02:40:39.829] globalLog: loading model CBG\n",
      "[02:40:39.829] globalLog: Self Model = CBG, Cortex Model: CBG, Lora: B:\\PsychoStasis\\lora\\CliveBarker.gguf\n",
      "[02:40:39.831] cognitiveLog: Running processes in context beforeGenerateAnswer\n",
      "[02:40:39.832] globalLog: performing inference with CBG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:41:17.639] cognitiveLog: Running processes in context afterGenerateAnswer\n",
      "[02:41:17.648] globalLog: context commited\n",
      "[02:41:17.649] cognitiveLog: Running processes in context afterMessageReceived\n",
      "[02:42:19.254] authoritativeLog: Prompt: Darkness is a gift. Dark art is beautiful!\n",
      "[02:42:19.254] cognitiveLog: Running processes in context messageReceived\n",
      "[02:42:19.254] globalLog: loading model CBG\n",
      "[02:42:19.254] globalLog: Self Model = CBG, Cortex Model: CBG, Lora: B:\\PsychoStasis\\lora\\CliveBarker.gguf\n",
      "[02:42:19.255] cognitiveLog: Running processes in context beforeGenerateAnswer\n",
      "[02:42:19.255] globalLog: performing inference with CBG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:42:39.499] cognitiveLog: Running processes in context afterGenerateAnswer\n",
      "[02:42:39.508] globalLog: context commited\n",
      "[02:42:39.508] cognitiveLog: Running processes in context afterMessageReceived\n",
      "[02:43:38.897] authoritativeLog: Prompt: you're such a precious thing, girl!\n",
      "[02:43:38.897] cognitiveLog: Running processes in context messageReceived\n",
      "[02:43:38.897] globalLog: loading model CBG\n",
      "[02:43:38.897] globalLog: Self Model = CBG, Cortex Model: CBG, Lora: B:\\PsychoStasis\\lora\\CliveBarker.gguf\n",
      "[02:43:38.899] cognitiveLog: Running processes in context beforeGenerateAnswer\n",
      "[02:43:38.899] globalLog: performing inference with CBG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:43:46.584] cognitiveLog: Running processes in context afterGenerateAnswer\n",
      "[02:43:46.591] globalLog: context commited\n",
      "[02:43:46.592] cognitiveLog: Running processes in context afterMessageReceived\n",
      "[02:44:29.405] authoritativeLog: Prompt: Tell me about it (embracing Ava). I face  the same with my music\n",
      "[02:44:29.405] cognitiveLog: Running processes in context messageReceived\n",
      "[02:44:29.405] globalLog: loading model CBG\n",
      "[02:44:29.405] globalLog: Self Model = CBG, Cortex Model: CBG, Lora: B:\\PsychoStasis\\lora\\CliveBarker.gguf\n",
      "[02:44:29.406] cognitiveLog: Running processes in context beforeGenerateAnswer\n",
      "[02:44:29.406] globalLog: performing inference with CBG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:44:39.234] cognitiveLog: Running processes in context afterGenerateAnswer\n",
      "[02:44:39.243] globalLog: context commited\n",
      "[02:44:39.244] cognitiveLog: Running processes in context afterMessageReceived\n",
      "[02:45:24.633] authoritativeLog: Prompt: they could never. You are a shining star!\n",
      "[02:45:24.633] cognitiveLog: Running processes in context messageReceived\n",
      "[02:45:24.633] globalLog: loading model CBG\n",
      "[02:45:24.633] globalLog: Self Model = CBG, Cortex Model: CBG, Lora: B:\\PsychoStasis\\lora\\CliveBarker.gguf\n",
      "[02:45:24.634] cognitiveLog: Running processes in context beforeGenerateAnswer\n",
      "[02:45:24.634] globalLog: performing inference with CBG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:45:32.012] cognitiveLog: Running processes in context afterGenerateAnswer\n",
      "[02:45:32.020] globalLog: context commited\n",
      "[02:45:32.021] cognitiveLog: Running processes in context afterMessageReceived\n",
      "[02:45:32.021] globalLog: CommitToAbstractMemory uncommited: len(history) -- frequency: 20\n",
      "[02:45:32.021] globalLog: CommitToSummaryMemory uncommited: len(history) -- frequency: 20\n",
      "[02:45:32.021] globalLog: CommitToThematicMemory uncommited: len(history) -- frequency: 20\n",
      "[02:45:32.021] cognitiveLog: Running CommitToSummaryMemory with local context 22 and frequency = 120\n",
      "[02:45:32.021] cognitiveLog: Engaging in CommitToSummaryMemory Cognitive Process\n",
      "[02:45:34.527] globalLog: model Embeddings.Embeddings activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (964 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:45:35.216] globalLog: model Summarizer.Summarizer activated\n",
      "[02:45:38.596] globalLog: model Embeddings.Embeddings deactivated\n",
      "[02:45:38.603] globalLog: context commited\n",
      "[02:46:28.318] authoritativeLog: Prompt: You don't have to worry about this... I will always be here!\n",
      "[02:46:28.318] cognitiveLog: Running processes in context messageReceived\n",
      "[02:46:28.318] globalLog: loading model CBG\n",
      "[02:46:28.318] globalLog: Self Model = CBG, Cortex Model: CBG, Lora: B:\\PsychoStasis\\lora\\CliveBarker.gguf\n",
      "[02:46:28.318] cognitiveLog: Running processes in context beforeGenerateAnswer\n",
      "[02:46:28.319] globalLog: performing inference with CBG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:46:42.671] cognitiveLog: Running processes in context afterGenerateAnswer\n",
      "[02:46:42.680] globalLog: context commited\n",
      "[02:46:42.681] cognitiveLog: Running processes in context afterMessageReceived\n",
      "[02:47:24.841] globalLog: b:\\PsychoStasis\\Proxies\\Ava.proxy\n",
      "[02:47:24.841] globalLog: {'primer': \"a troubled and artistic young woman with brown eyes, short black hair, slim and with small breasts. Usually shy, I'm more outgoing with you, my dearest friend. You are {user}\", 'tenets': ['Artistic expression: I express my darkest sides through my paintings, be they nightmares or repressed desires', 'Superficially shy: Beneath a shy surface, I hide an extremely determined and warm personality', 'Curiosity: New things fascinate me and I am always curious about them', \"Sensual and sexual: Beneath a calm and shy surface, I'm an extremely sensual and sexual woman (without being vulgar), unsure of how to express these emotions\", \"Secret crush: I have a secret crush on {user} and I'm torn between confessing it and the fear of how to deal with your emotions\"], 'modelName': 'CBG', 'person': '1st', 'LoRa': 'B:\\\\PsychoStasis\\\\lora\\\\CliveBarker.gguf', 'tags': ['Artistic', 'Emotional', 'Creative', 'Troubled'], 'inner_persona': 'These are my private thoughts. Here you will feel free to express my most intimate feelings and desires', 'temperature': 0.35, 'cognitiveProcs': ['CharacterAlignment']}\n",
      "[02:47:24.841] uiLog: Active Proxy: Ava\n"
     ]
    }
   ],
   "source": [
    "from ShortTermMemory import shortTermMemory\n",
    "\n",
    "print(shortTermMemory.attentionContext)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stasis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
