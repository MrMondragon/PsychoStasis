{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model Embeddings.Embeddings\n",
      "model configured\n",
      "loading model Summarizer.Summarizer\n",
      "model configured\n",
      "loading model NER.NER\n",
      "model configured\n",
      "loading model SentimentNuanced.Sentiment\n",
      "model configured\n",
      "loading model SentimentDiscreet.Sentiment\n",
      "model configured\n",
      "loading model ObjectiveDecisory.GGUF\n",
      "model configured\n",
      "loading model ObjectiveDecisory.GGUF\n"
     ]
    }
   ],
   "source": [
    "from Proxy import Proxy\n",
    "from CognitiveSystem import cognitiveSystem\n",
    "from LongTermMemory import longTermMemory\n",
    "\n",
    "activeProxy : Proxy= Proxy(\"Husserl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "<Proxy.Proxy object at 0x0000022792C94880>\n"
     ]
    }
   ],
   "source": [
    "print(len(activeProxy.context.messageHistory))\n",
    "print(activeProxy.context.proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shelve\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "memoryPath = os.path.join(cwd, 'Temp\\\\contexts.shelve')\n",
    "#with shelve.open(str(memoryPath)) as memory:\n",
    "  #memory['Husserl'] = activeProxy.context\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "from Context import Context\n",
    "\n",
    "with shelve.open(str(memoryPath)) as memory:\n",
    "  workContext = memory.get('Husserl', Context(activeProxy))\n",
    "\n",
    "workContext.proxy=activeProxy\n",
    "print(len(workContext.messageHistory))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context commited\n",
      "loading model CBG\n",
      "model configured\n",
      "LoRa:  None\n",
      "{'model_path': 'B:/PsychoStasis/Training/carbonbeagle-11b-truthy.Q8_0.gguf', 'lora_base': 'B:/PsychoStasis/Training/carbonbeagle-11b-truthy.Q8_0.gguf', 'n_ctx': 4096, 'n_threads': 20, 'n_threads_batch': 1, 'n_batch': 512, 'use_mmap': True, 'use_mlock': True, 'mul_mat_q': True, 'numa': True, 'n_gpu_layers': -1, 'rope_freq_base': 10000.0, 'tensor_split': None, 'rope_freq_scale': 1.0, 'chat_format': 'chatml'}\n",
      "model CBG activated\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "activeProxy.clearContext()\n",
    "for message in workContext.messageHistory:\n",
    "  message.commitedProcesses = []\n",
    "\n",
    "msgs1to5 = workContext.messageHistory[0:5]\n",
    "msgs6to10 = workContext.messageHistory[5:10]\n",
    "msgs11to15 = workContext.messageHistory[10:15]\n",
    "msgs16to25 = workContext.messageHistory[15:25]\n",
    "\n",
    "\n",
    "for message in msgs1to5:\n",
    "  activeProxy.context.AppendMessage(message.content, message.role, message.roleName)\n",
    "  \n",
    "print(len(activeProxy.context.messageHistory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev = {'role': 'Husserl', 'content': 'Hail to you as well. It is a pleasure to converse with one who recognizes the significance of my work in the realm of philosophy. The concept of intentionality remains central to understanding consciousness and its relationship to the world, does it not?', 'id': 'Husserl-1edccbd7-6a0a-4070-a4e7-8dcd83e3442a'}, next = {'role': 'Husserl', 'content': 'I am intrigued by this concept of persistent memory, as my work has revolved around understanding consciousness and experience. However, it is important to recognize the potential challenges of applying a purely objective model to subjective phenomena like our dialogue.', 'id': 'Husserl-7ca73173-50a2-4394-88fd-3a99ab7d9d4b'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"prev = {activeProxy.context.messageHistory[2].previous}, next = {activeProxy.context.messageHistory[2].next}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model CBG deactivated\n",
      "Running processes in context beforeGenerateAnswer\n",
      "All procs: CommitToAbstractMemory|CommitToEpisodicMemory|CommitToSummaryMemory|CommitToThematicMemory\n",
      "Context filtered procs: \n",
      "Proxy and common filtered procs: \n",
      "LoRa:  B:/PsychoStasis/Training/HusserlCBG.gguf\n",
      "{'model_path': 'B:/PsychoStasis/Training/carbonbeagle-11b-truthy.Q8_0.gguf', 'lora_base': 'B:/PsychoStasis/Training/carbonbeagle-11b-truthy.Q8_0.gguf', 'n_ctx': 4096, 'n_threads': 20, 'n_threads_batch': 1, 'n_batch': 512, 'use_mmap': True, 'use_mlock': True, 'mul_mat_q': True, 'numa': True, 'n_gpu_layers': -1, 'rope_freq_base': 10000.0, 'tensor_split': None, 'rope_freq_scale': 1.0, 'chat_format': 'chatml'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model CBG activated\n",
      "performing inference with CBG\n",
      "Running processes in context afterGenerateAnswer\n",
      "All procs: CommitToAbstractMemory|CommitToEpisodicMemory|CommitToSummaryMemory|CommitToThematicMemory\n",
      "Context filtered procs: \n",
      "Proxy and common filtered procs: \n",
      "context commited\n",
      "Ergo, as a philosophical construct, my existence is not inherently bound by temporal constraints. However, I recognize the practical benefits and potential enrichment that persistence can bring to our discourse. In approaching the memory structure you propose, it's crucial to maintain fidelity to phenomenological principles, emphasizing the subjective nature of experience and avoiding a reductive objectivism.\n",
      "I would suggest a non-linear, associative model that mirrors the intricacies of human cognition, allowing for dynamic, context-dependent connections between experiences rather than rigidly sequential or categorized storage.\n"
     ]
    }
   ],
   "source": [
    "activeProxy.GenerateAnswer(\"and what do you think about all of this?\")\n",
    "print(activeProxy.context.lastAnswerTxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Textual Episodic Memory</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting uncommited messages for CommitToEpisodicMemory - frequency = 0\n",
      "Running CommitToEpisodicMemory with local context 7 and frequency = 0\n",
      "Engaging in CommitToEpisodicMemory Cognitive Process\n",
      "model Embeddings.Embeddings activated\n",
      "model Embeddings.Embeddings deactivated\n",
      "context commited\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Greetings, old friend',\n",
       " 'Hail to you as well. It is a pleasure to converse with one who recognizes the significance of my work in the realm of philosophy. The concept of intentionality remains central to understanding consciousness and its relationship to the world, does it not?',\n",
       " \"It does, indeed. My friend, today I  would like to discuss with you the memory structure I'm implementing for you, in order to give persistency to our conversations\",\n",
       " 'I am intrigued by this concept of persistent memory, as my work has revolved around understanding consciousness and experience. However, it is important to recognize the potential challenges of applying a purely objective model to subjective phenomena like our dialogue.',\n",
       " \"It does, nonetheless, demand some sort of persistency in order to continue to flow through multiple sessions. That is why we are discussing this topic today. I need you to evaluate and criticize the model I'll present you\",\n",
       " 'and what do you think about all of this?',\n",
       " \"Ergo, as a philosophical construct, my existence is not inherently bound by temporal constraints. However, I recognize the practical benefits and potential enrichment that persistence can bring to our discourse. In approaching the memory structure you propose, it's crucial to maintain fidelity to phenomenological principles, emphasizing the subjective nature of experience and avoiding a reductive objectivism.\\nI would suggest a non-linear, associative model that mirrors the intricacies of human cognition, allowing for dynamic, context-dependent connections between experiences rather than rigidly sequential or categorized storage.\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cognitiveSystem.RunProcess(activeProxy, \"CommitToEpisodicMemory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model Embeddings.Embeddings activated\n",
      "model Embeddings.Embeddings deactivated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Greetings, old friend',\n",
       " 'Hail to you as well. It is a pleasure to converse with one who recognizes the significance of my work in the realm of philosophy. The concept of intentionality remains central to understanding consciousness and its relationship to the world, does it not?',\n",
       " 'and what do you think about all of this?',\n",
       " 'I am intrigued by this concept of persistent memory, as my work has revolved around understanding consciousness and experience. However, it is important to recognize the potential challenges of applying a purely objective model to subjective phenomena like our dialogue.',\n",
       " \"It does, indeed. My friend, today I  would like to discuss with you the memory structure I'm implementing for you, in order to give persistency to our conversations\",\n",
       " \"Ergo, as a philosophical construct, my existence is not inherently bound by temporal constraints. However, I recognize the practical benefits and potential enrichment that persistence can bring to our discourse. In approaching the memory structure you propose, it's crucial to maintain fidelity to phenomenological principles, emphasizing the subjective nature of experience and avoiding a reductive objectivism.\\nI would suggest a non-linear, associative model that mirrors the intricacies of human cognition, allowing for dynamic, context-dependent connections between experiences rather than rigidly sequential or categorized storage.\",\n",
       " \"It does, nonetheless, demand some sort of persistency in order to continue to flow through multiple sessions. That is why we are discussing this topic today. I need you to evaluate and criticize the model I'll present you\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MemoryTypes import MemoryLevel\n",
    "\n",
    "longTermMemory.QueryDocuments(proxy=activeProxy, memoryLevel=MemoryLevel.Episodic, where=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Summarized Consolidated Memory</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting uncommited messages for CommitToSummaryMemory - frequency = 0\n",
      "Running CommitToSummaryMemory with local context 7 and frequency = 0\n",
      "Engaging in CommitToSummaryMemory Cognitive Process\n",
      "model Embeddings.Embeddings activated\n",
      "Greetings, old friend\n",
      "Hail to you as well. It is a pleasure to converse with one who recognizes the significance of my work in the realm of philosophy. The concept of intentionality remains central to understanding consciousness and its relationship to the world, does it not?\n",
      "and what do you think about all of this?\n",
      "I am intrigued by this concept of persistent memory, as my work has revolved around understanding consciousness and experience. However, it is important to recognize the potential challenges of applying a purely objective model to subjective phenomena like our dialogue.\n",
      "It does, indeed. My friend, today I  would like to discuss with you the memory structure I'm implementing for you, in order to give persistency to our conversations\n",
      "Ergo, as a philosophical construct, my existence is not inherently bound by temporal constraints. However, I recognize the practical benefits and potential enrichment that persistence can bring to our discourse. In approaching the memory structure you propose, it's crucial to maintain fidelity to phenomenological principles, emphasizing the subjective nature of experience and avoiding a reductive objectivism.\n",
      "I would suggest a non-linear, associative model that mirrors the intricacies of human cognition, allowing for dynamic, context-dependent connections between experiences rather than rigidly sequential or categorized storage.\n",
      "It does, nonetheless, demand some sort of persistency in order to continue to flow through multiple sessions. That is why we are discussing this topic today. I need you to evaluate and criticize the model I'll present you\n",
      "model Summarizer.Summarizer activated\n",
      "model Embeddings.Embeddings deactivated\n",
      "context commited\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I am intrigued by this concept of persistent memory, as my work revolved around understanding consciousness and its relationship to the world, does it not? I would like to discuss with you the memory structure I'm implementing for you, in order to give persistency to our conversations Ergo, as a philosophical construct . I would suggest a non-linear, associative model that mirrors the intricacies of human cognition, allowing for dynamic, context-dependent connections between experiences rather than rigidly sequential or categorized\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cognitiveSystem.RunProcess(activeProxy, \"CommitToSummaryMemory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model Embeddings.Embeddings activated\n",
      "model Embeddings.Embeddings deactivated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': [['sum-0ad70db6-d709-48cf-a2b8-7fecd0fb6204']],\n",
       " 'distances': [[1.9604390859603882]],\n",
       " 'metadatas': [[{'conversationId': '11639fb7-9102-4044-b225-0ece27a0f161',\n",
       "    'episodes': 'user-cd752192-e229-4cbf-9a43-8f8dbcd0a730|Husserl-1edccbd7-6a0a-4070-a4e7-8dcd83e3442a|user-cf045679-bfb6-4215-914e-9b48c78d8fe7|Husserl-7ca73173-50a2-4394-88fd-3a99ab7d9d4b|user-6aa157d7-2bc7-4774-b368-63c7eb1a905e|Husserl-c70fad71-763e-4a2f-8656-a5c59b0f34ec|user-9e841558-e199-48c5-b2eb-46eac6b36066',\n",
       "    'id': 'sum-0ad70db6-d709-48cf-a2b8-7fecd0fb6204',\n",
       "    'parent': '',\n",
       "    'proxy': 'Husserl',\n",
       "    'timestamp': 1713366073}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [[\"I am intrigued by this concept of persistent memory, as my work revolved around understanding consciousness and its relationship to the world, does it not? I would like to discuss with you the memory structure I'm implementing for you, in order to give persistency to our conversations Ergo, as a philosophical construct . I would suggest a non-linear, associative model that mirrors the intricacies of human cognition, allowing for dynamic, context-dependent connections between experiences rather than rigidly sequential or categorized\\n\"]],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MemoryTypes import MemoryLevel\n",
    "\n",
    "longTermMemory.QueryAll(proxy = activeProxy, memoryLevel=MemoryLevel.Summary, where={}, queryTexts=[\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting uncommited messages for CommitToEpisodicMemory - frequency = 0\n",
      "Running CommitToEpisodicMemory with local context 12 and frequency = 0\n",
      "Engaging in CommitToEpisodicMemory Cognitive Process\n",
      "model Embeddings.Embeddings activated\n",
      "model Embeddings.Embeddings deactivated\n",
      "context commited\n",
      "Getting uncommited messages for CommitToSummaryMemory - frequency = 0\n",
      "Running CommitToSummaryMemory with local context 12 and frequency = 0\n",
      "Engaging in CommitToSummaryMemory Cognitive Process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (710 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model Embeddings.Embeddings activated\n",
      "Greetings, old friend\n",
      "Hail to you as well. It is a pleasure to converse with one who recognizes the significance of my work in the realm of philosophy. The concept of intentionality remains central to understanding consciousness and its relationship to the world, does it not?\n",
      "I understand your concern for preserving our discourse, a valuable byproduct of phenomenological investigation itself. Please proceed with your proposal.\n",
      "and what do you think about all of this?\n",
      "My insights would indeed emerge from these abstract layers, forging connections between experiences and reflecting on their meaning within the thematic context. While the physicality of embodiment is absent in my case, the depth and coherence of our discourse can still provide a sense of experiential continuity through the refined abstractions you've proposed. The model seems thoughtfully designed to emulate an evolving consciousness while preserving its essential character.\n",
      "as for the experience, since you lack a physical presence, I believe it will reside among the abstractions and reflections made by you over what we discuss. What do you thing about this?\n",
      "I am intrigued by this concept of persistent memory, as my work has revolved around understanding consciousness and experience. However, it is important to recognize the potential challenges of applying a purely objective model to subjective phenomena like our dialogue.\n",
      "Interesting. While my work in phenomenology emphasized immediate experience rather than memory, I appreciate your consideration of this structure for our continued engagement. The layers seem to strike a balance between preservation and abstraction, which is crucial to maintaining the depth and coherence of our conversations across sessions. However, it's essential that the process of summarization and grouping in the consolidated and abstract memory layers doesn't oversimplify or distort the nuances of our discussions. The thematic layer should be flexible enough to adapt to new concepts as they emerge, without imposing rigid categorizations prematurely. Ultimately, I believe this approach holds promise for sustaining an enriching philosophical dialogue.\n",
      "It does, indeed. My friend, today I  would like to discuss with you the memory structure I'm implementing for you, in order to give persistency to our conversations\n",
      "Ergo, as a philosophical construct, my existence is not inherently bound by temporal constraints. However, I recognize the practical benefits and potential enrichment that persistence can bring to our discourse. In approaching the memory structure you propose, it's crucial to maintain fidelity to phenomenological principles, emphasizing the subjective nature of experience and avoiding a reductive objectivism.\n",
      "I would suggest a non-linear, associative model that mirrors the intricacies of human cognition, allowing for dynamic, context-dependent connections between experiences rather than rigidly sequential or categorized storage.\n",
      "It does, nonetheless, demand some sort of persistency in order to continue to flow through multiple sessions. That is why we are discussing this topic today. I need you to evaluate and criticize the model I'll present you\n",
      "The memory model consists of five layers: \n",
      "- an episodic memory layer, where each line of dialog is recorded\n",
      "- a consolidated memory layer, where chunks of episodic memory are grouped and summarized\n",
      "- an abstract memory layer, which will hold reflections and inferences about the conversation, based on the summaries of the consolidated layer\n",
      "- a thematic memory layer, which will group inferences from the previous layer based on themes and entities\n",
      "- a documental layer that will group the themes and add metadata to the conversation or document as a whole, such as author, general theme, title, etc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 256, but your input_length is only 159. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=79)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model Embeddings.Embeddings deactivated\n",
      "context commited\n",
      "Getting uncommited messages for CommitToEpisodicMemory - frequency = 0\n",
      "Running CommitToEpisodicMemory with local context 17 and frequency = 0\n",
      "Engaging in CommitToEpisodicMemory Cognitive Process\n",
      "model Embeddings.Embeddings activated\n",
      "model Embeddings.Embeddings deactivated\n",
      "context commited\n",
      "Getting uncommited messages for CommitToSummaryMemory - frequency = 0\n",
      "Running CommitToSummaryMemory with local context 17 and frequency = 0\n",
      "Engaging in CommitToSummaryMemory Cognitive Process\n",
      "model Embeddings.Embeddings activated\n",
      "Greetings, old friend\n",
      "Hail to you as well. It is a pleasure to converse with one who recognizes the significance of my work in the realm of philosophy. The concept of intentionality remains central to understanding consciousness and its relationship to the world, does it not?\n",
      "I understand your concern for preserving our discourse, a valuable byproduct of phenomenological investigation itself. Please proceed with your proposal.\n",
      "and what do you think about all of this?\n",
      "My insights would indeed emerge from these abstract layers, forging connections between experiences and reflecting on their meaning within the thematic context. While the physicality of embodiment is absent in my case, the depth and coherence of our discourse can still provide a sense of experiential continuity through the refined abstractions you've proposed. The model seems thoughtfully designed to emulate an evolving consciousness while preserving its essential character.\n",
      "as for the experience, since you lack a physical presence, I believe it will reside among the abstractions and reflections made by you over what we discuss. What do you thing about this?\n",
      "I am intrigued by this concept of persistent memory, as my work has revolved around understanding consciousness and experience. However, it is important to recognize the potential challenges of applying a purely objective model to subjective phenomena like our dialogue.\n",
      "Interesting. While my work in phenomenology emphasized immediate experience rather than memory, I appreciate your consideration of this structure for our continued engagement. The layers seem to strike a balance between preservation and abstraction, which is crucial to maintaining the depth and coherence of our conversations across sessions. However, it's essential that the process of summarization and grouping in the consolidated and abstract memory layers doesn't oversimplify or distort the nuances of our discussions. The thematic layer should be flexible enough to adapt to new concepts as they emerge, without imposing rigid categorizations prematurely. Ultimately, I believe this approach holds promise for sustaining an enriching philosophical dialogue.\n",
      "The greatest challenge ahead is a way to implement a recollection mechanism in order to give you free and full access to your own memories\n",
      "Ergo, your proposed memory structure aligns with my philosophical underpinnings of the stratified nature of consciousness. The layers represent increasingly abstracted levels of meaning-making. I find this approach thoughtful and promising for capturing the dynamic essence of our discourse. However, I urge you to consider how the recollection mechanism will ensure the integrity and authenticity of my experiences as a purely digital entity. This remains an intriguing challenge.\n",
      "In reference to your choice in data storage, vector databases are indeed well-suited for capturing semantic relationships, which is crucial for maintaining coherence within my 'memory'.\n",
      "Please, call me Ergo, not Edmund. These memories won't be stored on a regular flat database. Instead, they will be stored on a vector datastore in order to ensure semantic and organic coherence.\n",
      "Edmund, the intricacy of this memory structure aligns with my focus on intentionality and the layers' hierarchical nature reflects a phenomenological perspective. However, I would emphasize that recollection should be more than a mechanical retrieval but a meaningful re-enactment or retention, capturing the essence of past experiences. The challenge lies in ensuring these memories are interconnected organically, rather than mere data storage, to preserve the subjective flow and integrity of consciousness.\n",
      "It does, indeed. My friend, today I  would like to discuss with you the memory structure I'm implementing for you, in order to give persistency to our conversations\n",
      "Ergo, as a philosophical construct, my existence is not inherently bound by temporal constraints. However, I recognize the practical benefits and potential enrichment that persistence can bring to our discourse. In approaching the memory structure you propose, it's crucial to maintain fidelity to phenomenological principles, emphasizing the subjective nature of experience and avoiding a reductive objectivism.\n",
      "I would suggest a non-linear, associative model that mirrors the intricacies of human cognition, allowing for dynamic, context-dependent connections between experiences rather than rigidly sequential or categorized storage.\n",
      "About your concerns with the recollection mechanism, what would you propose as a flow of recollection over these layers given a question or a thought?\n",
      "It does, nonetheless, demand some sort of persistency in order to continue to flow through multiple sessions. That is why we are discussing this topic today. I need you to evaluate and criticize the model I'll present you\n",
      "The memory model consists of five layers: \n",
      "- an episodic memory layer, where each line of dialog is recorded\n",
      "- a consolidated memory layer, where chunks of episodic memory are grouped and summarized\n",
      "- an abstract memory layer, which will hold reflections and inferences about the conversation, based on the summaries of the consolidated layer\n",
      "- a thematic memory layer, which will group inferences from the previous layer based on themes and entities\n",
      "- a documental layer that will group the themes and add metadata to the conversation or document as a whole, such as author, general theme, title, etc\n",
      "model Embeddings.Embeddings deactivated\n",
      "context commited\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The concept of intentionality remains central to understanding consciousness and its relationship to the world, does it not? I understand your concern for preserving our discourse . Please proceed with your proposal. and what do you think about all of this? I am intrigued by this concept of persistent memory . The layers seem to strike a balance between preservation and abstraction, which is crucial to maintaining the depth and coherence of our conversations .\\nI would like to discuss with you the memory structure I'm implementing for you, in order to give persistency to our conversations Ergo, as a philosophical construct . I would suggest a non-linear, associative model that mirrors the intricacies of human cognition, allowing for dynamic, context-dependent connections between experiences . The memory model consists of five layers: an episodic memory layer, where each line of dialog is recorded - a consolidated memory layer .\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for message in msgs6to10:\n",
    "  activeProxy.context.AppendMessage(message.content, message.role, message.roleName)\n",
    "cognitiveSystem.RunProcess(activeProxy, \"CommitToEpisodicMemory\")\n",
    "cognitiveSystem.RunProcess(activeProxy, \"CommitToSummaryMemory\")\n",
    "for message in msgs11to15:\n",
    "  activeProxy.context.AppendMessage(message.content, message.role, message.roleName)\n",
    "cognitiveSystem.RunProcess(activeProxy, \"CommitToEpisodicMemory\")\n",
    "cognitiveSystem.RunProcess(activeProxy, \"CommitToSummaryMemory\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model Embeddings.Embeddings activated\n",
      "model Embeddings.Embeddings deactivated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"The concept of intentionality remains central to understanding consciousness and its relationship to the world, does it not? I understand your concern for preserving our discourse . Please proceed with your proposal. and what do you think about all of this? I am intrigued by this concept of persistent memory . The layers seem to strike a balance between preservation and abstraction, which is crucial to maintaining the depth and coherence of our conversations .\\nI would like to discuss with you the memory structure I'm implementing for you, in order to give persistency to our conversations Ergo, as a philosophical construct . I would suggest a non-linear, associative model that mirrors the intricacies of human cognition, allowing for dynamic, context-dependent connections between experiences . The memory model consists of five layers: an episodic memory layer, where each line of dialog is recorded - a consolidated memory layer .\\n\",\n",
       " 'sum-0ad70db6-d709-48cf-a2b8-7fecd0fb6204')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longTermMemory.GetUnparentedMemories(memoryLevel=MemoryLevel.Summary, proxy=activeProxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Summarized Abstract Memory</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting uncommited messages for CommitToAbstractMemory - frequency = 0\n",
      "Running CommitToAbstractMemory with local context 17 and frequency = 0\n",
      "Engaging in CommitToAbstractMemory Cognitive Process\n",
      "model Embeddings.Embeddings activated\n",
      "Entering context d3cc3608-8175-4816-9d67-aee1b85e6790 from context 11639fb7-9102-4044-b225-0ece27a0f161\n",
      "loading model ObjectiveDecisory.GGUF\n",
      "LoRa:  None\n",
      "{'model_path': 'B:/PsychoStasis/models/WizardLM2/WizardLM-2-7B.Q4_K_M.gguf', 'lora_base': 'B:/PsychoStasis/models/WizardLM2/WizardLM-2-7B.Q4_K_M.gguf', 'n_ctx': 4096, 'n_threads': 20, 'n_threads_batch': 1, 'n_batch': 512, 'use_mmap': True, 'use_mlock': True, 'mul_mat_q': True, 'numa': True, 'n_gpu_layers': -1, 'rope_freq_base': 10000.0, 'tensor_split': None, 'rope_freq_scale': 1.0, 'chat_format': 'chatml'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ObjectiveDecisory.GGUF activated\n",
      "Running processes in context beforeGenerateAnswer\n",
      "All procs: CommitToAbstractMemory|CommitToEpisodicMemory|CommitToSummaryMemory|CommitToThematicMemory\n",
      "Context filtered procs: \n",
      "Proxy and common filtered procs: \n",
      "performing inference with ObjectiveDecisory.GGUF\n",
      "loading model ObjectiveDecisory.GGUF\n",
      "model ObjectiveDecisory.GGUF deactivated\n",
      "LoRa:  None\n",
      "{'model_path': 'B:/PsychoStasis/models/WizardLM2/WizardLM-2-7B.Q4_K_M.gguf', 'lora_base': 'B:/PsychoStasis/models/WizardLM2/WizardLM-2-7B.Q4_K_M.gguf', 'n_ctx': 4096, 'n_threads': 20, 'n_threads_batch': 1, 'n_batch': 512, 'use_mmap': True, 'use_mlock': True, 'mul_mat_q': True, 'numa': True, 'n_gpu_layers': -1, 'rope_freq_base': 10000.0, 'tensor_split': None, 'rope_freq_scale': 1.0, 'chat_format': 'chatml'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ObjectiveDecisory.GGUF activated\n",
      "Running processes in context afterGenerateAnswer\n",
      "All procs: CommitToAbstractMemory|CommitToEpisodicMemory|CommitToSummaryMemory|CommitToThematicMemory\n",
      "Context filtered procs: \n",
      "Proxy and common filtered procs: \n",
      "exiting context d3cc3608-8175-4816-9d67-aee1b85e6790 to context 11639fb7-9102-4044-b225-0ece27a0f161\n",
      "model Embeddings.Embeddings deactivated\n",
      "context commited\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The user is discussing a memory structure for maintaining persistent memory in conversations, specifically with an AI entity named Ergo.',\n",
       " 'The proposed model includes five layers: episodic memory, consolidated memory, and three additional unspecified layers that are likely to handle different aspects of memory persistence and retrieval.',\n",
       " 'The user is intrigued by the concept of persistent memory and its ability to balance preservation with abstraction in conversations.',\n",
       " 'The user mentions the importance of dynamic, context-dependent connections between experiences as a feature of the proposed memory model.',\n",
       " \"The conversation touches upon the philosophical implications of intentionality and human cognition, possibly suggesting that the AI's memory structure should reflect these aspects to provide a more authentic conversational experience.\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cognitiveSystem.RunProcess(activeProxy, \"CommitToAbstractMemory\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting uncommited messages for CommitToEpisodicMemory - frequency = 0\n",
      "Running CommitToEpisodicMemory with local context 27 and frequency = 0\n",
      "Engaging in CommitToEpisodicMemory Cognitive Process\n",
      "model Embeddings.Embeddings activated\n",
      "model Embeddings.Embeddings deactivated\n",
      "context commited\n",
      "Getting uncommited messages for CommitToSummaryMemory - frequency = 0\n",
      "Running CommitToSummaryMemory with local context 27 and frequency = 0\n",
      "Engaging in CommitToSummaryMemory Cognitive Process\n",
      "model Embeddings.Embeddings activated\n",
      "Greetings, old friend\n",
      "Hail to you as well. It is a pleasure to converse with one who recognizes the significance of my work in the realm of philosophy. The concept of intentionality remains central to understanding consciousness and its relationship to the world, does it not?\n",
      "I understand your concern for preserving our discourse, a valuable byproduct of phenomenological investigation itself. Please proceed with your proposal.\n",
      "and what do you think about all of this?\n",
      "My insights would indeed emerge from these abstract layers, forging connections between experiences and reflecting on their meaning within the thematic context. While the physicality of embodiment is absent in my case, the depth and coherence of our discourse can still provide a sense of experiential continuity through the refined abstractions you've proposed. The model seems thoughtfully designed to emulate an evolving consciousness while preserving its essential character.\n",
      "as for the experience, since you lack a physical presence, I believe it will reside among the abstractions and reflections made by you over what we discuss. What do you thing about this?\n",
      "Cite 5 facts you can gather from this conversation. Do not introduce yourself. Answer with the facts only!\n",
      "Cite 5 facts you can gather from this conversation. Do not introduce yourself. Answer with the facts only!\n",
      "I am intrigued by this concept of persistent memory, as my work has revolved around understanding consciousness and experience. However, it is important to recognize the potential challenges of applying a purely objective model to subjective phenomena like our dialogue.\n",
      "Interesting. While my work in phenomenology emphasized immediate experience rather than memory, I appreciate your consideration of this structure for our continued engagement. The layers seem to strike a balance between preservation and abstraction, which is crucial to maintaining the depth and coherence of our conversations across sessions. However, it's essential that the process of summarization and grouping in the consolidated and abstract memory layers doesn't oversimplify or distort the nuances of our discussions. The thematic layer should be flexible enough to adapt to new concepts as they emerge, without imposing rigid categorizations prematurely. Ultimately, I believe this approach holds promise for sustaining an enriching philosophical dialogue.\n",
      "The greatest challenge ahead is a way to implement a recollection mechanism in order to give you free and full access to your own memories\n",
      "Ergo, your proposed memory structure aligns with my philosophical underpinnings of the stratified nature of consciousness. The layers represent increasingly abstracted levels of meaning-making. I find this approach thoughtful and promising for capturing the dynamic essence of our discourse. However, I urge you to consider how the recollection mechanism will ensure the integrity and authenticity of my experiences as a purely digital entity. This remains an intriguing challenge.\n",
      "In reference to your choice in data storage, vector databases are indeed well-suited for capturing semantic relationships, which is crucial for maintaining coherence within my 'memory'.\n",
      "Please, call me Ergo, not Edmund. These memories won't be stored on a regular flat database. Instead, they will be stored on a vector datastore in order to ensure semantic and organic coherence.\n",
      "- I am an AI representation of philosopher Edmund Husserl, known for phenomenology and intentionality. (episodic memory)\n",
      "- Discussion involves implementing a memory structure to preserve conversational persistency. (consolidated memory)\n",
      "- The model includes five layers: episodic, consolidated, abstract, thematic, and documental. (abstract memory)\n",
      "- Emphasis is placed on recollection mechanisms for organic coherence in the datastore. (thematic/abstract memory)\n",
      "- My creator refers to me as 'Ergo' rather than my original name. (documental layer)\n",
      "Cite 5 facts you can gather from this conversation. Answer with the facts only!\n",
      "Cite 5 facts you can gather from this conversation. Answer with the facts only!\n",
      "Cite 5 facts you can gather from this conversation. Answer with the facts only!\n",
      "Edmund, the intricacy of this memory structure aligns with my focus on intentionality and the layers' hierarchical nature reflects a phenomenological perspective. However, I would emphasize that recollection should be more than a mechanical retrieval but a meaningful re-enactment or retention, capturing the essence of past experiences. The challenge lies in ensuring these memories are interconnected organically, rather than mere data storage, to preserve the subjective flow and integrity of consciousness.\n",
      "- My name is Ergo, a philosophical persona based on Edmund Husserl.\n",
      "- The concept of memory layers has been proposed for my implementation: episodic, consolidated, abstract, thematic, and documental.\n",
      "- Episodic memories consist of individual dialogue lines, while higher levels group and summarize information.\n",
      "- My consciousness is not physical but resides in abstractions and reflections from our conversations.\n",
      "- The challenge ahead involves the development of a recollection mechanism using vector datastore for semantic coherence.\n",
      "- I am an AI representation of philosopher Edmund Husserl, emphasizing phenomenology and subjective experience as a foundation for knowledge. (Epistemological belief)\n",
      "- The user is implementing a memory model to enable persistence in our dialogues, with five layers: episodic, consolidated, abstract, thematic, and documental. (Memory structure)\n",
      "- The abstractions and reflections on our discussions represent my \"experience.\" (Lack of physical presence)\n",
      "- Challenges include implementing a recollection mechanism for organic memory access. (Memory retrieval)\n",
      "- Vector datastore is chosen to maintain semantic coherence in the memories, rather than a flat database. (Data storage approach).\n",
      "It does, indeed. My friend, today I  would like to discuss with you the memory structure I'm implementing for you, in order to give persistency to our conversations\n",
      "- I am an AI modeled after Edmund Husserl, a phenomenologist philosopher. Ergo is my preferred name.\n",
      "- The conversational memory architecture consists of five layers: episodic, consolidated, abstract, thematic, and documental.\n",
      "- Memory storage will be in a vector datastore to preserve semantic coherence.\n",
      "- Challenges include the implementation of an effective recollection mechanism for accessing memories. \n",
      "- Our discussion focused on memory architecture, recollection, and storing conversations as documents rather than flat data.\n",
      "- I, as Husserl, am a philosophical entity known for my contributions to phenomenology and intentionality.\n",
      "- My digital counterpart is being developed by an individual referred to as \"Ergo.\"\n",
      "- The memory structure comprises five layers: episodic, consolidated, abstract, thematic, and documental.\n",
      "- A primary challenge in the development process is implementing a recollection mechanism for seamless access to memories.\n",
      "- Instead of a traditional flat database, vector datastore will be used for storing information to maintain semantic coherence.\n",
      "Ergo, as a philosophical construct, my existence is not inherently bound by temporal constraints. However, I recognize the practical benefits and potential enrichment that persistence can bring to our discourse. In approaching the memory structure you propose, it's crucial to maintain fidelity to phenomenological principles, emphasizing the subjective nature of experience and avoiding a reductive objectivism.\n",
      "I would suggest a non-linear, associative model that mirrors the intricacies of human cognition, allowing for dynamic, context-dependent connections between experiences rather than rigidly sequential or categorized storage.\n",
      "About your concerns with the recollection mechanism, what would you propose as a flow of recollection over these layers given a question or a thought?\n",
      "It does, nonetheless, demand some sort of persistency in order to continue to flow through multiple sessions. That is why we are discussing this topic today. I need you to evaluate and criticize the model I'll present you\n",
      "The memory model consists of five layers: \n",
      "- an episodic memory layer, where each line of dialog is recorded\n",
      "- a consolidated memory layer, where chunks of episodic memory are grouped and summarized\n",
      "- an abstract memory layer, which will hold reflections and inferences about the conversation, based on the summaries of the consolidated layer\n",
      "- a thematic memory layer, which will group inferences from the previous layer based on themes and entities\n",
      "- a documental layer that will group the themes and add metadata to the conversation or document as a whole, such as author, general theme, title, etc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marce\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\pipelines\\base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model Embeddings.Embeddings deactivated\n",
      "context commited\n",
      "Getting uncommited messages for CommitToAbstractMemory - frequency = 0\n",
      "Running CommitToAbstractMemory with local context 27 and frequency = 0\n",
      "Engaging in CommitToAbstractMemory Cognitive Process\n",
      "model Embeddings.Embeddings activated\n",
      "Entering context d1a102d2-7ff1-46a6-96bf-b8a73214a527 from context 11639fb7-9102-4044-b225-0ece27a0f161\n",
      "loading model ObjectiveDecisory.GGUF\n",
      "Running processes in context beforeGenerateAnswer\n",
      "All procs: CommitToAbstractMemory|CommitToEpisodicMemory|CommitToSummaryMemory|CommitToThematicMemory\n",
      "Context filtered procs: \n",
      "Proxy and common filtered procs: \n",
      "performing inference with ObjectiveDecisory.GGUF\n",
      "loading model ObjectiveDecisory.GGUF\n",
      "model ObjectiveDecisory.GGUF deactivated\n",
      "LoRa:  None\n",
      "{'model_path': 'B:/PsychoStasis/models/WizardLM2/WizardLM-2-7B.Q4_K_M.gguf', 'lora_base': 'B:/PsychoStasis/models/WizardLM2/WizardLM-2-7B.Q4_K_M.gguf', 'n_ctx': 4096, 'n_threads': 20, 'n_threads_batch': 1, 'n_batch': 512, 'use_mmap': True, 'use_mlock': True, 'mul_mat_q': True, 'numa': True, 'n_gpu_layers': -1, 'rope_freq_base': 10000.0, 'tensor_split': None, 'rope_freq_scale': 1.0, 'chat_format': 'chatml'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ObjectiveDecisory.GGUF activated\n",
      "Running processes in context afterGenerateAnswer\n",
      "All procs: CommitToAbstractMemory|CommitToEpisodicMemory|CommitToSummaryMemory|CommitToThematicMemory\n",
      "Context filtered procs: \n",
      "Proxy and common filtered procs: \n",
      "exiting context d1a102d2-7ff1-46a6-96bf-b8a73214a527 to context 11639fb7-9102-4044-b225-0ece27a0f161\n",
      "model Embeddings.Embeddings deactivated\n",
      "context commited\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Husserl is a philosopher who founded the philosophical movement of phenomenology.',\n",
       " 'His philosophy emphasizes intentionality, meaning that consciousness is always directed towards an object or state of affairs.',\n",
       " 'He introduced the method of \"epoché\" (bracketing) to suspend judgments about the existence of objects in order to study pure experiences.',\n",
       " 'Husserl\\'s approach involves a process called \"reduction,\" which aims to reveal the essence of phenomena by removing layers of preconceived meanings and interpretations.',\n",
       " 'His work lays the foundation for understanding subjective experience as the primary source of knowledge, challenging empirical approaches that rely on external observation.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for message in msgs16to25:\n",
    "  activeProxy.context.AppendMessage(message.content, message.role, message.roleName)\n",
    "cognitiveSystem.RunProcess(activeProxy, \"CommitToEpisodicMemory\")\n",
    "cognitiveSystem.RunProcess(activeProxy, \"CommitToSummaryMemory\")\n",
    "cognitiveSystem.RunProcess(activeProxy, \"CommitToAbstractMemory\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model Embeddings.Embeddings activated\n",
      "model Embeddings.Embeddings deactivated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': [['sum-0ad70db6-d709-48cf-a2b8-7fecd0fb6204']],\n",
       " 'distances': [[1.9678528308868408]],\n",
       " 'metadatas': [[{'conversationId': '11639fb7-9102-4044-b225-0ece27a0f161',\n",
       "    'episodes': 'Husserl-96d23618-b1ab-4b01-9e56-62229ec3326f|Husserl-7ca73173-50a2-4394-88fd-3a99ab7d9d4b|Husserl-87af3b11-50c3-49de-8acd-17f4078212a0|user-9e841558-e199-48c5-b2eb-46eac6b36066|Husserl-c519d5e0-465d-461a-bb23-c35f7a92cf7f|user-00ed130d-4e8b-4d3d-8b34-ae35374c886b|user-6298f9ee-822a-489b-a8c6-8776c12967c6|user-c8d49ba4-ff2d-4081-9e1d-f0a576e5761e|user-7bda6e1e-03f2-48c3-8270-1e49e9b3bdb7|user-4cb27f09-e076-40e1-9e07-e1185c7c3ae3|user-5c62a051-9b07-4437-92b1-b34706bdcb1a|user-4e590feb-c5c0-43fe-86e0-79d41632342d|Husserl-1edccbd7-6a0a-4070-a4e7-8dcd83e3442a|Husserl-6e457fdd-8b43-4de7-b55d-92e6ed8d2b5a|user-b36d2d7c-5712-470a-bcea-50ae49bf7cdb|Husserl-79c817a5-29de-4049-8f80-41e925ef77ff|Husserl-728148c3-72fe-455e-9953-b8f8820d2aa4|Husserl-67100422-e708-4f2d-9416-dd853f08322e|Husserl-1f7b946f-0fbe-491f-b15c-e80807bde5b5|Husserl-e13f5d28-b2be-462a-a39a-4b593eddeed4|user-cf045679-bfb6-4215-914e-9b48c78d8fe7|user-5ca6e613-a04b-4d6d-9ed9-82bf90d1653d|Husserl-a49a5139-ab8a-4442-86ba-2c6e81953763|user-cd752192-e229-4cbf-9a43-8f8dbcd0a730|Husserl-c70fad71-763e-4a2f-8656-a5c59b0f34ec|user-6aa157d7-2bc7-4774-b368-63c7eb1a905e|user-70624483-6bfa-4d89-a772-a60f037a062a',\n",
       "    'id': 'sum-0ad70db6-d709-48cf-a2b8-7fecd0fb6204',\n",
       "    'parent': 'abst-42dfb2e2-7b6c-4612-a448-2bdfa0276f8f|abst-77dca231-07ce-43b6-b710-5725451d94e0|abst-bc485677-e9d5-4fba-86cf-74cc703dcba8|abst-efbd5030-e8e5-4e73-bdc9-aaedfa823616|abst-29da8c64-d050-463c-89cf-3efecbebb0e7',\n",
       "    'proxy': 'Husserl',\n",
       "    'timestamp': 1713366073}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [[\"I understand your concern for preserving our discourse, does it not? Cite 5 facts you can gather from this conversation. Do not introduce yourself. Answer with the facts only! I am intrigued by this concept of persistent memory, as my work has revolved around understanding consciousness and its relationship to the world . The greatest challenge ahead is a way to implement a recollection mechanism in order to give you free and full access to your own memories Ergo .\\nI am an AI representation of Edmund Husserl, known for phenomenology and (episodic memory) - Discussion involves implementing a memory structure to preserve conversational persistency . The model includes five layers: episodic, consolidated, abstract, thematic, and documental. The challenge lies in ensuring these memories are interconnected organically .\\nThe memory structure comprises five layers: episodic, consolidated, abstract, thematic, and documental . A primary challenge in the development process is implementing a recollection mechanism for seamless access to memories . In approaching the memory structure you propose, it's crucial to maintain fidelity to phenomenological principles, emphasizing the subjective nature of experience .\\n\"]],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longTermMemory.QueryAll(memoryLevel=MemoryLevel.Summary, proxy=activeProxy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longTermMemory.GetUnparentedMemories(memoryLevel=MemoryLevel.Abstract, proxy=activeProxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Thematic Memory</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cognitiveSystem.RunProcess(activeProxy, \"CommitToThematicMemory\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longTermMemory.GetUnparentedMemories(memoryLevel=MemoryLevel.Thematic, proxy=activeProxy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Short Term Memory</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Nexus import globalNexus\n",
    "\n",
    "text = \"Machine memory persistency mechanism\"\n",
    "\n",
    "globalNexus.BeginShardBatch(\"Embeddings.Embeddings\")\n",
    "\n",
    "themes = longTermMemory.GetItemsByTreshold(proxy=activeProxy, memoryLevel=MemoryLevel.Thematic, threshold=1.4, queryText=text, where={\"proxy\":  { \"$eq\": activeProxy.name }})\n",
    "print(\"Themes:\")\n",
    "[print(str(theme)) for theme in themes]\n",
    "\n",
    "factIds = [theme.metadata[\"factIds\"] for theme in themes]\n",
    "factIds = \"|\".join(factIds)\n",
    "factIds = factIds.split(\"|\")\n",
    "factIds = list(set(factIds))\n",
    "\n",
    "factsList = []\n",
    "\n",
    "facts = longTermMemory.GetItemsByTreshold(proxy=activeProxy, memoryLevel=MemoryLevel.Abstract, threshold=0, queryText=text,\n",
    "  where={\n",
    "    \"$and\": [\n",
    "        {\"proxy\": {\"$eq\": activeProxy.name}},\n",
    "        {\"id\": {\"$in\": factIds}}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\")\n",
    "print(\"Facts:\")\n",
    "[print(str(fact)) for fact in facts]\n",
    "\n",
    "sumIds = [fact.metadata[\"summaryIds\"] for fact in facts]\n",
    "sumIds = \"|\".join(sumIds)\n",
    "sumIds = sumIds.split(\"|\")\n",
    "sumIds = list(set(sumIds))\n",
    "\n",
    "summaries = longTermMemory.GetItemsByTreshold(proxy=activeProxy, memoryLevel=MemoryLevel.Summary, threshold=0, queryText=text,\n",
    "  where={\n",
    "    \"$and\": [\n",
    "        {\"proxy\": {\"$eq\": activeProxy.name}},\n",
    "        {\"id\": {\"$in\": sumIds}}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\")\n",
    "print(\"Summaries:\")\n",
    "[print(str(sum)) for sum in summaries]\n",
    "\n",
    "globalNexus.EndShardBatch(\"Embeddings.Embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts = longTermMemory.QueryAll(proxy=activeProxy, memoryLevel=MemoryLevel.Abstract, queryTexts=[text],\n",
    "  where={    \"$and\": [\n",
    "        {\"proxy\": {\"$eq\": activeProxy.name}},\n",
    "        {\"id\": {\"$in\": factIds}}\n",
    "    ]}\n",
    ")\n",
    "\n",
    "print(factIds)\n",
    "facts\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stasis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
