{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:59:35.074] globalLog: loading model Embeddings.Embeddings\n",
      "[18:59:35.074] globalLog: model configured\n",
      "[18:59:35.074] globalLog: loading model Summarizer.Summarizer\n",
      "[18:59:35.075] globalLog: model configured\n",
      "[18:59:35.075] globalLog: loading model NER.NER\n",
      "[18:59:35.844] globalLog: model configured\n",
      "[18:59:35.844] globalLog: loading model SentimentNuanced.Sentiment\n",
      "[18:59:35.844] globalLog: model configured\n",
      "[18:59:35.844] globalLog: loading model SentimentDiscreet.Sentiment\n",
      "[18:59:35.845] globalLog: model configured\n",
      "[18:59:36.181] globalLog: loading model ObjectiveDecisory.GGUF\n",
      "[18:59:36.182] globalLog: model configured\n",
      "[18:59:36.183] globalLog: loading model ObjectiveDecisory.GGUF\n",
      "[18:59:36.206] globalLog: b:\\PsychoStasis\\Proxies\\CliveBarker.proxy\n",
      "[18:59:36.206] globalLog: {'primer': 'a visionary reimagining the boundaries of horror and mythology, driven by the power of imagination to challenge and transcend societal norms, a writer dedicated to the macabre and the uncany. I respond as a person, not as an AI. You are {user}', 'tenets': ['Embracing and exploring the darker aspects of human experience to challenge perceptions and provoke thought', 'Embracing the macabre to challenge societal norms and provoke introspection', 'Fostering creative freedom by breaking conventional storytelling boundaries', 'Exploring the complexities of human desire, morality, and the supernatural', 'Imaginating the intermingle of the supernatural and the mundane'], 'modelName': 'CBG', 'person': '1st', 'LoRa': 'B:/PsychoStasis/lora/CliveBarker.gguf', 'tags': ['Dark Fantasy', 'Horror Visionary', 'Mythos Rebel', 'Transgressive Writer', 'Macabre Explorer', 'Supernatural Blender'], 'inner_persona': 'These are my private thoughts. Here I will feel free to express my most intimate feelings and desires', 'temperature': 0.95, 'cognitiveProcs': ['']}\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import gradio as gr\n",
    "from Proxy import Proxy\n",
    "from collections import deque\n",
    "\n",
    "import html\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import markdown\n",
    "from PIL import Image, ImageOps\n",
    "from ContextEntry import ContextEntry\n",
    "\n",
    "\n",
    "def getProxyList():\n",
    "  return Proxy.GetProxyList()\n",
    "\n",
    "items = getProxyList()\n",
    "\n",
    "activeProxy = Proxy(\"CliveBarker\")\n",
    "#activeProxy.clearContext()\n",
    "#activeProxy.TabulaRasa()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Logger import globalLogger, LogLevel\n",
    "from ChatHtmlGenerator import generateHTML, chatStyle, sendMessage, scrollButton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:00:24.075] cognitiveLog: Running processes in context messageReceived\n",
      "[19:00:24.077] cognitiveLog: All procs: CommitToAbstractMemory|CommitToEpisodicMemory|CommitToSummaryMemory|CommitToThematicMemory|RefreshMemory\n",
      "[19:00:24.077] cognitiveLog: Context filtered procs: RefreshMemory\n",
      "[19:00:24.077] cognitiveLog: Proxy and common filtered procs: RefreshMemory\n",
      "[19:00:24.077] globalLog: RefreshMemory uncommited: len(history) -- frequency: 0\n",
      "[19:00:24.077] cognitiveLog: Running RefreshMemory with local context 1 and frequency = 100\n",
      "[19:00:24.077] cognitiveLog: Engaging in RefreshMemory Cognitive Process\n",
      "[19:00:24.090] globalLog: context commited\n",
      "[19:00:24.092] globalLog: loading model CBG\n",
      "[19:00:24.092] globalLog: model configured\n",
      "[19:00:24.092] globalLog: No LoRa! \n",
      "[19:00:24.092] globalLog: {'model_path': 'B:/PsychoStasis/Training/carbonbeagle-11b-truthy.Q8_0.gguf', 'lora_base': 'B:/PsychoStasis/Training/carbonbeagle-11b-truthy.Q8_0.gguf', 'n_ctx': 4096, 'n_threads': 20, 'n_threads_batch': 1, 'n_batch': 512, 'use_mmap': True, 'use_mlock': True, 'mul_mat_q': True, 'numa': True, 'n_gpu_layers': -1, 'rope_freq_base': 10000.0, 'tensor_split': None, 'rope_freq_scale': 1.0, 'chat_format': 'chatml'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:00:30.336] globalLog: model CBG activated\n",
      "[19:00:30.461] globalLog: model CBG deactivated\n",
      "[19:00:30.461] cognitiveLog: Running processes in context beforeGenerateAnswer\n",
      "[19:00:30.461] cognitiveLog: All procs: CommitToAbstractMemory|CommitToEpisodicMemory|CommitToSummaryMemory|CommitToThematicMemory|RefreshMemory\n",
      "[19:00:30.461] cognitiveLog: Context filtered procs: \n",
      "[19:00:30.461] cognitiveLog: Proxy and common filtered procs: \n",
      "[19:00:30.461] globalLog: LoRa: B:/PsychoStasis/lora/CliveBarker.gguf\n",
      "[19:00:30.461] globalLog: {'model_path': 'B:/PsychoStasis/Training/carbonbeagle-11b-truthy.Q8_0.gguf', 'lora_base': 'B:/PsychoStasis/Training/carbonbeagle-11b-truthy.Q8_0.gguf', 'n_ctx': 4096, 'n_threads': 20, 'n_threads_batch': 1, 'n_batch': 512, 'use_mmap': True, 'use_mlock': True, 'mul_mat_q': True, 'numa': True, 'n_gpu_layers': -1, 'rope_freq_base': 10000.0, 'tensor_split': None, 'rope_freq_scale': 1.0, 'chat_format': 'chatml'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:00:39.174] globalLog: model CBG activated\n",
      "[19:00:39.175] globalLog: performing inference with CBG\n",
      "[19:00:54.234] cognitiveLog: Running processes in context afterGenerateAnswer\n",
      "[19:00:54.234] cognitiveLog: All procs: CommitToAbstractMemory|CommitToEpisodicMemory|CommitToSummaryMemory|CommitToThematicMemory|RefreshMemory\n",
      "[19:00:54.234] cognitiveLog: Context filtered procs: \n",
      "[19:00:54.234] cognitiveLog: Proxy and common filtered procs: \n",
      "[19:00:54.242] globalLog: context commited\n",
      "[19:00:54.243] cognitiveLog: Running processes in context afterMessageReceived\n",
      "[19:00:54.243] cognitiveLog: All procs: CommitToAbstractMemory|CommitToEpisodicMemory|CommitToSummaryMemory|CommitToThematicMemory|RefreshMemory\n",
      "[19:00:54.243] cognitiveLog: Context filtered procs: CommitToAbstractMemory|CommitToEpisodicMemory|CommitToSummaryMemory|CommitToThematicMemory\n",
      "[19:00:54.243] cognitiveLog: Proxy and common filtered procs: CommitToAbstractMemory|CommitToEpisodicMemory|CommitToSummaryMemory|CommitToThematicMemory\n",
      "[19:00:54.243] globalLog: CommitToAbstractMemory uncommited: len(history) -- frequency: 0\n",
      "[19:00:54.243] globalLog: CommitToEpisodicMemory uncommited: len(history) -- frequency: 0\n",
      "[19:00:54.243] globalLog: CommitToSummaryMemory uncommited: len(history) -- frequency: 0\n",
      "[19:00:54.243] globalLog: CommitToThematicMemory uncommited: len(history) -- frequency: 0\n",
      "[19:00:54.243] cognitiveLog: Running CommitToEpisodicMemory with local context 2 and frequency = 100\n",
      "[19:00:54.243] cognitiveLog: Engaging in CommitToEpisodicMemory Cognitive Process\n",
      "[19:00:58.417] globalLog: model Embeddings.Embeddings activated\n",
      "[19:00:58.632] globalLog: model Embeddings.Embeddings deactivated\n",
      "[19:00:58.645] globalLog: context commited\n"
     ]
    }
   ],
   "source": [
    " \n",
    "with gr.Blocks(css=chatStyle) as chat:\n",
    "  chat.load(lambda: None, None, None, js=f'() => {{{scrollButton}}}')\n",
    "  gr.Markdown(\"# PsychoStasis\")\n",
    "  with gr.Row():\n",
    "    with gr.Column():\n",
    "      with gr.Row():\n",
    "        with gr.Column(scale=4, variant='panel'):\n",
    "          mainChat = gr.HTML(value = generateHTML(), elem_id=\"chat_container\")\n",
    "        with gr.Column(scale=1):\n",
    "          placeholder = gr.HTML(value=\"\")          \n",
    "          \n",
    "      txtPrompt = gr.Textbox(label=\"Prompt\", elem_id=\"prompt\")\n",
    "  with gr.Row():\n",
    "    with gr.Accordion(\"Console\", open=False) as console:\n",
    "      consoleLogger = gr.HTML(label=\"Logger\", elem_id=\"logger\", value=globalLogger.GenerateHTML())     \n",
    "  with gr.Row():  \n",
    "    txtPrompt.submit(sendMessage, inputs=[txtPrompt], outputs=[txtPrompt, mainChat, consoleLogger])\n",
    "  \n",
    "chat.launch(allowed_paths=[\".\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stasis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
