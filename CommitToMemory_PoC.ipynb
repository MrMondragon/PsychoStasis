{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model Embeddings.Embeddings already deactivated\n",
      "model Summarizer.Summarizer already deactivated\n",
      "model NER.NER already deactivated\n",
      "Tokenizing with global model\n",
      "Message: in c# we have a trim() method in the string class to remove trailing and starting empty spaces from a string. What is the correspondent method in python?\n",
      "Tokenizing with global model\n",
      "Message: In Python, there isn't a built-in `trim()` method like in C#. However, you can achieve the same result by using the `strip()` function or `lstrip()` and `rstrip()` functions which are equivalent to `Trim()`, `TrimStart()`, and `TrimEnd()` respectively in C#.\n",
      "\n",
      "Here's how you would use them:\n",
      "\n",
      "```python\n",
      "str = \"   Hello World   \"\n",
      "print(str.strip())  # Removes leading and trailing spaces\n",
      "print(str.lstrip())  # Removes only leading spaces\n",
      "print(str.rstrip())  # Removes only trailing spaces\n",
      "```\n",
      "Tokenizing with global model\n",
      "Message: give me a regular expression to detect the following: the string representation for numbers One to Ten and literal numbers, including decimals\n",
      "Tokenizing with global model\n",
      "Message: In Python, you can use the `re` module to work with Regular Expressions. Here's an example of how you might create a regular expression that matches strings representing numbers from one to ten (in words or digits) as well as decimal numbers:\n",
      "\n",
      "```python\n",
      "import re\n",
      "\n",
      "def is_number(n):\n",
      "    number_pattern = r\"^(one|two|three|four|five|six|seven|eight|nine|ten|1[0-9]?|20|0\\.[1-9])$|^([0-9]{1,3}(,[0-9]{3})*(\\.[0-9]+)?)$\"\n",
      "    return bool(re.match(number_pattern, n, re.IGNORECASE))\n",
      "```\n",
      "This regular expression works as follows:\n",
      "\n",
      "- `^` asserts the start of a line.\n",
      "- `one|two|three|four|five|six|seven|eight|nine|ten` matches any of these words (case insensitive due to `re.IGNORECASE`).\n",
      "- `1[0-9]?|20` matches numbers from 10 to 20.\n",
      "- `0\\.[1-9]` matches decimal numbers between 0 and 1, excluding 0 itself (e.g., 0.5, 0.7).\n",
      "- `([0-9]{1,3}(,[0-9]{3})*(\\.[0-9]+)?)` matches any number from 0 to 999,999,999 with optional grouping of digits by thousands (e.g., 1,000,000) and decimal part.\n",
      "- `$` asserts the end of a line.\n",
      "\n",
      "Please note that this regular expression will match numbers in the range from 0 to 20 inclusive, as well as any number with up to three digits before the decimal point and one or more digits after it. If you need to match larger numbers, you can adjust the `{1,3}` part of the regular expression accordingly.\n",
      "```\n",
      "Tokenizing with global model\n",
      "Message: now, considering I have this regular expression string loaded in a variable named pattern, show me how can I replace values in a string using this pattern regex\n",
      "Tokenizing with global model\n",
      "Message: You can use the `re.sub()` function to replace matched substrings with another substring. Here's an example of how you might do it:\n",
      "\n",
      "```python\n",
      "import re\n",
      "\n",
      "# Your regular expression pattern\n",
      "pattern = r\"your_regular_expression_here\"\n",
      "\n",
      "# The string in which you want to make replacements\n",
      "text = \"your text here\"\n",
      "\n",
      "# The substring that will replace the matched substrings\n",
      "replacement = \"your replacement text here\"\n",
      "\n",
      "new_text = re.sub(pattern, replacement, text)\n",
      "```\n",
      "\n",
      "In this example, `re.sub()` will find all occurrences of the pattern in the input string and replace them with the specified replacement substring. The result is stored in `new_text`.\n",
      "\n",
      "Please note that you need to replace \"your_regular_expression_here\", \"your text here\" and \"your replacement text here\" with your actual regular expression, input string and replacement string respectively.\n",
      "Tokenizing with global model\n",
      "Message: what arguments can I pass to the strip method in python?\n",
      "Tokenizing with global model\n",
      "Message: The `strip()` function in Python removes leading and trailing spaces from a string by default. However, you can also specify characters that should be removed using the `strip()` method. This is done by passing these characters as an argument to the `strip()` method.\n",
      "\n",
      "Here's how you can use it:\n",
      "\n",
      "```python\n",
      "str = \"---Hello World---\"\n",
      "print(str.strip('-'))  # Removes leading and trailing '-'\n",
      "```\n",
      "\n",
      "In this example, all hyphens at the beginning and end of the string are removed because they were passed as an argument to `strip()`.\n",
      "\n",
      "If you don't pass any arguments to `strip()`, it will remove spaces from both ends of the string:\n",
      "\n",
      "```python\n",
      "str = \"   Hello World    \"\n",
      "print(str.strip())  # Removes leading and trailing spaces\n",
      "```\n",
      "\n",
      "In this case, all spaces at the beginning and end of the string are removed because no arguments were passed to `strip()`.\n",
      "\n",
      "\n",
      "Tokenizing with global model\n",
      "Message: what arguments can I pass to the strip method in python?\n",
      "Tokenizing with global model\n",
      "Message: The `strip()` function in Python removes leading and trailing spaces from a string by default. However, you can also specify characters that should be removed using the `strip()` method. This is done by passing these characters as an argument to the `strip()` method.\n",
      "\n",
      "Here's how you can use it:\n",
      "\n",
      "```python\n",
      "str = \"---Hello World---\"\n",
      "print(str.strip('-'))  # Removes leading and trailing '-'\n",
      "```\n",
      "\n",
      "In this example, all hyphens at the beginning and end of the string are removed because they were passed as an argument to `strip()`.\n",
      "\n",
      "If you don't pass any arguments to `strip()`, it will remove spaces from both ends of the string:\n",
      "\n",
      "```python\n",
      "str = \"   Hello World    \"\n",
      "print(str.strip())  # Removes leading and trailing spaces\n",
      "```\n",
      "\n",
      "In this case, all spaces at the beginning and end of the string are removed because no arguments were passed to `strip()`.\n",
      "\n",
      "\n",
      "Tokenizing with global model\n",
      "Message: can I specify more than one character? or does this need to be done in different calls?\n",
      "Tokenizing with global model\n",
      "Message: You can pass multiple characters as an argument to the `strip()` method, but they will all be treated as a single string. Here's how you can do it:\n",
      "\n",
      "```python\n",
      "str = \"---Hello World---\"\n",
      "print(str.strip('-='))  # Removes leading and trailing '-' or '='\n",
      "```\n",
      "\n",
      "In this example, both hyphens (`-`) and equals signs (`=`) at the beginning and end of the string are removed because they were passed as an argument to `strip()`. The characters are treated as a single string, so if any character in the string matches one of these characters, it will be removed.\n",
      "\n",
      "If you want to remove different sets of characters from the start or end of the string, you would need to make separate calls to `strip()`:\n",
      "\n",
      "```python\n",
      "str = \"---Hello World===\"\n",
      "print(str.strip('-').strip('='))  # Removes leading '-' and trailing '='\n",
      "```\n",
      "\n",
      "In this example, hyphens are removed from the start of the string by one call to `strip()`, and equals signs are removed from the end of the string by a second call to `strip()`. The result is that all hyphens at the beginning and all equals signs at the end of the string are removed.\n",
      "\n",
      "Tokenizing with global model\n",
      "Message: I have a list of strings named searchList. Write a lambda expression to make every string in this list become enclosed in double quotes\n",
      "Tokenizing with global model\n",
      "Message: You can use Python's `map()` function along with a lambda expression to achieve this. Here is how you can do it:\n",
      "\n",
      "```python\n",
      "searchList = [\"string1\", \"string2\", \"string3\"]\n",
      "\n",
      "# Use map and lambda to add double quotes around each string in the list\n",
      "searchList = list(map(lambda x: '\"' + x + '\"', searchList))\n",
      "\n",
      "print(searchList)  # Outputs: ['\"string1\"', '\"string2\"', '\"string3\"']\n",
      "```\n",
      "\n",
      "In this code, `map()` applies a lambda function to each item in the list. The lambda function takes an input (in this case, a string from the list), adds double quotes around it, and returns the result. The `list()` function is used to convert the map object back into a list.\n",
      "\n",
      "Tokenizing with global model\n",
      "Message: You know,  I feel bad during valentines day since my wife went away\n",
      "Tokenizing with global model\n",
      "Message: Sorry to hear it, Liam.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from Proxy import Proxy\n",
    "proxy = Proxy(name=\"Ergo\")\n",
    "\n",
    "\n",
    "proxy.context.append_message(message=\"\"\"in c# we have a trim() method in the string class to remove trailing and starting empty spaces from a string. What is the correspondent method in python?\"\"\", role=\"user\")\n",
    "proxy.context.append_message(message=\"\"\"In Python, there isn't a built-in `trim()` method like in C#. However, you can achieve the same result by using the `strip()` function or `lstrip()` and `rstrip()` functions which are equivalent to `Trim()`, `TrimStart()`, and `TrimEnd()` respectively in C#.\n",
    "\n",
    "Here's how you would use them:\n",
    "\n",
    "```python\n",
    "str = \"   Hello World   \"\n",
    "print(str.strip())  # Removes leading and trailing spaces\n",
    "print(str.lstrip())  # Removes only leading spaces\n",
    "print(str.rstrip())  # Removes only trailing spaces\n",
    "```\"\"\", role=\"assistant\")\n",
    "\n",
    "proxy.context.append_message(message=\"\"\"give me a regular expression to detect the following: the string representation for numbers One to Ten and literal numbers, including decimals\"\"\", role=\"user\")\n",
    "proxy.context.append_message(message='''In Python, you can use the `re` module to work with Regular Expressions. Here's an example of how you might create a regular expression that matches strings representing numbers from one to ten (in words or digits) as well as decimal numbers:\n",
    "\n",
    "```python\n",
    "import re\n",
    "\n",
    "def is_number(n):\n",
    "    number_pattern = r\"^(one|two|three|four|five|six|seven|eight|nine|ten|1[0-9]?|20|0\\.[1-9])$|^([0-9]{1,3}(,[0-9]{3})*(\\.[0-9]+)?)$\"\n",
    "    return bool(re.match(number_pattern, n, re.IGNORECASE))\n",
    "```\n",
    "This regular expression works as follows:\n",
    "\n",
    "- `^` asserts the start of a line.\n",
    "- `one|two|three|four|five|six|seven|eight|nine|ten` matches any of these words (case insensitive due to `re.IGNORECASE`).\n",
    "- `1[0-9]?|20` matches numbers from 10 to 20.\n",
    "- `0\\.[1-9]` matches decimal numbers between 0 and 1, excluding 0 itself (e.g., 0.5, 0.7).\n",
    "- `([0-9]{1,3}(,[0-9]{3})*(\\.[0-9]+)?)` matches any number from 0 to 999,999,999 with optional grouping of digits by thousands (e.g., 1,000,000) and decimal part.\n",
    "- `$` asserts the end of a line.\n",
    "\n",
    "Please note that this regular expression will match numbers in the range from 0 to 20 inclusive, as well as any number with up to three digits before the decimal point and one or more digits after it. If you need to match larger numbers, you can adjust the `{1,3}` part of the regular expression accordingly.\n",
    "```''', role=\"assistant\")\n",
    "\n",
    "proxy.context.append_message(message=\"\"\"now, considering I have this regular expression string loaded in a variable named pattern, show me how can I replace values in a string using this pattern regex\"\"\", role=\"user\")\n",
    "proxy.context.append_message(message='''You can use the `re.sub()` function to replace matched substrings with another substring. Here's an example of how you might do it:\n",
    "\n",
    "```python\n",
    "import re\n",
    "\n",
    "# Your regular expression pattern\n",
    "pattern = r\"your_regular_expression_here\"\n",
    "\n",
    "# The string in which you want to make replacements\n",
    "text = \"your text here\"\n",
    "\n",
    "# The substring that will replace the matched substrings\n",
    "replacement = \"your replacement text here\"\n",
    "\n",
    "new_text = re.sub(pattern, replacement, text)\n",
    "```\n",
    "\n",
    "In this example, `re.sub()` will find all occurrences of the pattern in the input string and replace them with the specified replacement substring. The result is stored in `new_text`.\n",
    "\n",
    "Please note that you need to replace \"your_regular_expression_here\", \"your text here\" and \"your replacement text here\" with your actual regular expression, input string and replacement string respectively.''', role=\"assistant\")\n",
    "\n",
    "proxy.context.append_message(message=\"\"\"what arguments can I pass to the strip method in python?\"\"\", role=\"user\")\n",
    "proxy.context.append_message(message='''The `strip()` function in Python removes leading and trailing spaces from a string by default. However, you can also specify characters that should be removed using the `strip()` method. This is done by passing these characters as an argument to the `strip()` method.\n",
    "\n",
    "Here's how you can use it:\n",
    "\n",
    "```python\n",
    "str = \"---Hello World---\"\n",
    "print(str.strip('-'))  # Removes leading and trailing '-'\n",
    "```\n",
    "\n",
    "In this example, all hyphens at the beginning and end of the string are removed because they were passed as an argument to `strip()`.\n",
    "\n",
    "If you don't pass any arguments to `strip()`, it will remove spaces from both ends of the string:\n",
    "\n",
    "```python\n",
    "str = \"   Hello World    \"\n",
    "print(str.strip())  # Removes leading and trailing spaces\n",
    "```\n",
    "\n",
    "In this case, all spaces at the beginning and end of the string are removed because no arguments were passed to `strip()`.\n",
    "\n",
    "''', role=\"assistant\")\n",
    "\n",
    "proxy.context.append_message(message=\"\"\"what arguments can I pass to the strip method in python?\"\"\", role=\"user\")\n",
    "proxy.context.append_message(message='''The `strip()` function in Python removes leading and trailing spaces from a string by default. However, you can also specify characters that should be removed using the `strip()` method. This is done by passing these characters as an argument to the `strip()` method.\n",
    "\n",
    "Here's how you can use it:\n",
    "\n",
    "```python\n",
    "str = \"---Hello World---\"\n",
    "print(str.strip('-'))  # Removes leading and trailing '-'\n",
    "```\n",
    "\n",
    "In this example, all hyphens at the beginning and end of the string are removed because they were passed as an argument to `strip()`.\n",
    "\n",
    "If you don't pass any arguments to `strip()`, it will remove spaces from both ends of the string:\n",
    "\n",
    "```python\n",
    "str = \"   Hello World    \"\n",
    "print(str.strip())  # Removes leading and trailing spaces\n",
    "```\n",
    "\n",
    "In this case, all spaces at the beginning and end of the string are removed because no arguments were passed to `strip()`.\n",
    "\n",
    "''', role=\"assistant\")\n",
    "\n",
    "proxy.context.append_message(message=\"\"\"can I specify more than one character? or does this need to be done in different calls?\"\"\", role=\"user\")\n",
    "proxy.context.append_message(message='''You can pass multiple characters as an argument to the `strip()` method, but they will all be treated as a single string. Here's how you can do it:\n",
    "\n",
    "```python\n",
    "str = \"---Hello World---\"\n",
    "print(str.strip('-='))  # Removes leading and trailing '-' or '='\n",
    "```\n",
    "\n",
    "In this example, both hyphens (`-`) and equals signs (`=`) at the beginning and end of the string are removed because they were passed as an argument to `strip()`. The characters are treated as a single string, so if any character in the string matches one of these characters, it will be removed.\n",
    "\n",
    "If you want to remove different sets of characters from the start or end of the string, you would need to make separate calls to `strip()`:\n",
    "\n",
    "```python\n",
    "str = \"---Hello World===\"\n",
    "print(str.strip('-').strip('='))  # Removes leading '-' and trailing '='\n",
    "```\n",
    "\n",
    "In this example, hyphens are removed from the start of the string by one call to `strip()`, and equals signs are removed from the end of the string by a second call to `strip()`. The result is that all hyphens at the beginning and all equals signs at the end of the string are removed.\n",
    "''', role=\"assistant\")\n",
    "\n",
    "lastMessage = \"\"\"I have a list of strings named searchList. Write a lambda expression to make every string in this list become enclosed in double quotes\"\"\"\n",
    "proxy.context.append_message(message=lastMessage, role=\"user\")\n",
    "answer = '''You can use Python's `map()` function along with a lambda expression to achieve this. Here is how you can do it:\n",
    "\n",
    "```python\n",
    "searchList = [\"string1\", \"string2\", \"string3\"]\n",
    "\n",
    "# Use map and lambda to add double quotes around each string in the list\n",
    "searchList = list(map(lambda x: '\"' + x + '\"', searchList))\n",
    "\n",
    "print(searchList)  # Outputs: ['\"string1\"', '\"string2\"', '\"string3\"']\n",
    "```\n",
    "\n",
    "In this code, `map()` applies a lambda function to each item in the list. The lambda function takes an input (in this case, a string from the list), adds double quotes around it, and returns the result. The `list()` function is used to convert the map object back into a list.\n",
    "'''\n",
    "proxy.context.append_message(message=answer, role=\"assistant\")\n",
    "\n",
    "lastMessage = \"\"\"You know,  I feel bad during valentines day since my wife went away\"\"\"\n",
    "proxy.context.append_message(message=lastMessage, role=\"user\")\n",
    "answer = '''Sorry to hear it, Liam.'''\n",
    "proxy.context.append_message(message=answer, role=\"assistant\")\n",
    "proxy.context.last_answer = answer\n",
    "proxy.context.last_message = lastMessage\n",
    "proxy.context.proxy = proxy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decisory Prompt for commiting to memmory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default - {'total:24.0, free:9.868804931640625, used:14.131195068359375 --- 2024-02-22 04:11:59.332865'}\n",
      "model OpenOrca already deactivated\n",
      "Loaded - {'total:24.0, free:9.864830017089844, used:14.135169982910156 --- 2024-02-22 04:11:59.347634'}\n"
     ]
    }
   ],
   "source": [
    "from Nexus import globalNexus\n",
    "print(f\"Default - {globalNexus.get_memory_usage()}\")\n",
    "globalNexus.load_model(\"OpenOrca\")\n",
    "print(f\"Loaded - {globalNexus.get_memory_usage()}\")\n",
    "#globalNexus.activate_model(\"OpenOrca\")\n",
    "#print(f\"Reactivated - {globalNexus.get_memory_usage()}\")\n",
    "#globalNexus.deactivate_model(\"OpenOrca\")\n",
    "#print(f\"Deactivated - {globalNexus.get_memory_usage()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before - {'total:24.0, free:2.807445526123047, used:21.192554473876953 --- 2024-02-22 04:14:43.742596'}\n",
      "model Llama2 deactivated\n",
      "After - {'total:24.0, free:2.803295135498047, used:21.196704864501953 --- 2024-02-22 04:14:43.868696'}\n",
      "True\n",
      "Entering context 3bf413f5-c6d5-4230-b453-9241a58f86f7 from context bb60dc26-5a6b-4957-b898-0118f8da5b9b\n",
      "model OpenOrca already activated\n",
      "Tokenizing with local model\n",
      "OpenOrca\n",
      "Tokenizing with local model\n",
      "OpenOrca\n",
      "Tokenizing with local model\n",
      "OpenOrca\n",
      "performing inference with OpenOrca\n",
      "model OpenOrca already activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "Llama._create_completion: cache save\n",
      "Llama.save_state: saving llama state\n",
      "Llama.save_state: got state size: 4309369772\n",
      "Llama.save_state: allocated state\n",
      "Llama.save_state: copied llama state: 38258304\n",
      "Llama.save_state: saving 38258304 bytes of llama state\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep active:True\n",
      "exiting context 3bf413f5-c6d5-4230-b453-9241a58f86f7 to context bb60dc26-5a6b-4957-b898-0118f8da5b9b\n",
      "\n",
      "\n",
      "Personal messages are a form of communication between individuals, usually through digital platforms like social media, instant messaging apps, or email. These messages are often private and not intended for a wider audience, making them a convenient way for people to share their thoughts, feelings, and updates in a more informal and personal setting.\n",
      "Before - {'total:24.0, free:0.6588249206542969, used:23.341175079345703 --- 2024-02-22 04:14:48.884007'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model Llama2 activated\n",
      "After - {'total:24.0, free:15.204818725585938, used:8.795181274414062 --- 2024-02-22 04:15:04.095887'}\n"
     ]
    }
   ],
   "source": [
    "from Nexus import globalNexus\n",
    "#print(f\"Before - {globalNexus.get_memory_usage()}\")\n",
    "#globalNexus.CortexModel.activate()\n",
    "#print(f\"After - {globalNexus.get_memory_usage()}\")\n",
    "#print(f\"Layers: {globalNexus.CortexModel.params['n-gpu-layers']}\")\n",
    "\n",
    "shard = \"OpenOrca\"\n",
    "proxy.context.verbose=False\n",
    "print(f\"Before - {globalNexus.get_memory_usage()}\")\n",
    "proxy.deactivateCortex()\n",
    "print(f\"After - {globalNexus.get_memory_usage()}\")\n",
    "\n",
    "globalNexus.ShardModels[shard].keepActive = True\n",
    "\n",
    "print(globalNexus.ShardModels[shard].keepActive)\n",
    "proxy.enterSubContext()\n",
    "proxy.context.systemMessage = proxy.GenerateSystem()\n",
    "personal = proxy.GenerateAnswer(shard=shard,prompt=\"define personal messages\")\n",
    "proxy.exitSubContext()\n",
    "print(personal)\n",
    "\n",
    "print(f\"Before - {globalNexus.get_memory_usage()}\")\n",
    "proxy.activateCortex()\n",
    "print(f\"After - {globalNexus.get_memory_usage()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model Llama2 deactivated\n",
      "Entering context 84e77400-9129-46d1-b2af-4135177027ea from context bb60dc26-5a6b-4957-b898-0118f8da5b9b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model OpenOrca activated\n",
      "Tokenizing with local model\n",
      "OpenOrca\n",
      "Tokenizing with local model\n",
      "OpenOrca\n",
      "Tokenizing with local model\n",
      "OpenOrca\n",
      "performing inference with OpenOrca\n",
      "model OpenOrca already activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama._create_completion: cache miss\n",
      "Llama._create_completion: cache save\n",
      "Llama.save_state: saving llama state\n",
      "Llama.save_state: got state size: 4346364084\n",
      "Llama.save_state: allocated state\n",
      "Llama.save_state: copied llama state: 104482564\n",
      "Llama.save_state: saving 104482564 bytes of llama state\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep active:True\n",
      "exiting context 84e77400-9129-46d1-b2af-4135177027ea to context bb60dc26-5a6b-4957-b898-0118f8da5b9b\n",
      "Entering context 57cc3872-4525-49e9-8d04-2f282db4ade8 from context bb60dc26-5a6b-4957-b898-0118f8da5b9b\n",
      "model OpenOrca already activated\n",
      "Tokenizing with local model\n",
      "OpenOrca\n",
      "Tokenizing with local model\n",
      "OpenOrca\n",
      "Tokenizing with local model\n",
      "OpenOrca\n",
      "performing inference with OpenOrca\n",
      "model OpenOrca already activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "Llama._create_completion: cache save\n",
      "Llama.save_state: saving llama state\n",
      "Llama.save_state: got state size: 4346364084\n",
      "Llama.save_state: allocated state\n",
      "Llama.save_state: copied llama state: 110118832\n",
      "Llama.save_state: saving 110118832 bytes of llama state\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep active:True\n",
      "exiting context 57cc3872-4525-49e9-8d04-2f282db4ade8 to context bb60dc26-5a6b-4957-b898-0118f8da5b9b\n",
      "Entering context 9953f496-ec2b-4ecf-a5ae-f0bb499e4de8 from context bb60dc26-5a6b-4957-b898-0118f8da5b9b\n",
      "model OpenOrca already activated\n",
      "Tokenizing with local model\n",
      "OpenOrca\n",
      "Tokenizing with local model\n",
      "OpenOrca\n",
      "Tokenizing with local model\n",
      "OpenOrca\n",
      "performing inference with OpenOrca\n",
      "model OpenOrca already activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "Llama._create_completion: cache save\n",
      "Llama.save_state: saving llama state\n",
      "Llama.save_state: got state size: 4346364084\n",
      "Llama.save_state: allocated state\n",
      "Llama.save_state: copied llama state: 109856680\n",
      "Llama.save_state: saving 109856680 bytes of llama state\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep active:True\n",
      "exiting context 9953f496-ec2b-4ecf-a5ae-f0bb499e4de8 to context bb60dc26-5a6b-4957-b898-0118f8da5b9b\n",
      "model OpenOrca deactivated\n",
      "programming related: Yes\n",
      "explicit request: No\n",
      "personal: Yes\n"
     ]
    }
   ],
   "source": [
    "from Memory import globalMemory\n",
    "\n",
    "from Nexus import globalNexus\n",
    "\n",
    "globalNexus.CortexModel.params[\"grammar_string\"] = '''root ::= choice\n",
    "choice ::= \"Yes\"|\"No\"'''\n",
    "\n",
    "shard = \"OpenOrca\"\n",
    "if(shard):\n",
    "  globalNexus.ShardModels[shard].params[\"grammar_string\"] = globalNexus.CortexModel.params[\"grammar_string\"]\n",
    "  globalNexus.ShardModels[shard].keepActive = True\n",
    "  proxy.deactivateCortex()\n",
    "else:\n",
    "  proxy.activateCortex()\n",
    "  \n",
    "  \n",
    "\n",
    "#globalNexus.CortexModel.activate()\n",
    "#globalNexus.CortexModel.deactivate()\n",
    "proxy.context.verbose=False\n",
    "proxy.enterSubContext(deepCopy=False)\n",
    "\n",
    "#localContext=proxy.context.parentContext.message_history[-2:]\n",
    "localContext=proxy.context.parentContext.message_history[-8:-5]\n",
    "proxy.context.systemMessage = proxy.GenerateSystem()\n",
    "proxy.context.message_history.extend(localContext)\n",
    "programmingRelated = proxy.GenerateAnswer(shard=shard,prompt=\"Are the previous messages about programming doubts or any such immediate tasks? Answer wtih Yes or No only!\")\n",
    "proxy.exitSubContext()\n",
    "\n",
    "proxy.enterSubContext(deepCopy=False)\n",
    "proxy.context.systemMessage = proxy.GenerateSystem()\n",
    "proxy.context.message_history.extend(localContext)\n",
    "personal = proxy.GenerateAnswer(shard=shard,prompt=\"\"\"Personal messages are messages in which the user confides facts about his life.\n",
    "Intimate messages are the ones where the user and the assistant are discussing their feelings and positions about a point of view.\n",
    "Based on this information were the previous messages of intimate or personal nature? Answer wtih Yes or No only!\"\"\")\n",
    "proxy.exitSubContext()\n",
    "\n",
    "proxy.enterSubContext(deepCopy=False)\n",
    "proxy.context.systemMessage = proxy.GenerateSystem()\n",
    "proxy.context.message_history.extend(localContext)\n",
    "explicitRequest = proxy.GenerateAnswer(shard=shard,prompt=\"\"\"Messages like 'you should remember...' or 'please remember' or 'be aware that...'\n",
    "or 'Note that...' represent things the user needs you to remember.\n",
    "Based on these examples, are there points the user wants you to remember in the previous messages? Answer wtih Yes or No only!\"\"\")\n",
    "proxy.exitSubContext()\n",
    "\n",
    "globalNexus.ShardModels[\"OpenOrca\"].keepActive = False\n",
    "globalNexus.deactivate_model(\"OpenOrca\")\n",
    "\n",
    "\n",
    "print(f\"\"\"programming related: {programmingRelated}\n",
    "explicit request: {explicitRequest}\n",
    "personal: {personal}\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalNexus.CortexModel.params[\"grammar_string\"] =''\n",
    "proxy.enterSubContext(deepCopy=False)\n",
    "proxy.context.systemMessage = proxy.GenerateSystem()\n",
    "proxy.context.message_history.extend(localContext)\n",
    "facts = proxy.GenerateAnswer(prompt=\"Cite two facts you can gather from this conversation\")\n",
    "proxy.exitSubContext()\n",
    "print(facts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Enter and Exit sub context tests***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(proxy.context.message_history)\n",
    "print(proxy.context.parentContext)\n",
    "print(proxy.context.contextID)\n",
    "proxy.enterSubContext(deepCopy=False)\n",
    "print(proxy.context.message_history)\n",
    "print(proxy.context.parentContext)\n",
    "print(proxy.context.contextID)\n",
    "proxy.exitSubContext()\n",
    "print(proxy.context.contextID)\n",
    "print(proxy.context.message_history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conversation slicing in messages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"describe this portion of our conversation:\"\n",
    "print(proxy.context.get_token_count(prompt=prompt))\n",
    "\n",
    "proxy.enterSubContext(deepCopy=True)\n",
    "chunks = range(proxy.context.GetChunkCount(chunkSize=4))\n",
    "print(chunks)\n",
    "responses = []\n",
    "\n",
    "for i in chunks:\n",
    "  contextChunk = proxy.context.getChunks(chunkSize=4, chunkIndex=i)\n",
    "  print(contextChunk)\n",
    "  proxy.context.systemMessage = \"\"\n",
    "  proxy.enterSubContext(deepCopy=False)\n",
    "  proxy.context.systemMessage = \"\"\n",
    "  proxy.context.message_history=contextChunk\n",
    "  description = proxy.GenerateAnswer(prompt=prompt)\n",
    "  responses.append(description)\n",
    "  proxy.exitSubContext()\n",
    "\n",
    "proxy.exitSubContext()\n",
    "\n",
    "\n",
    "print(str.join(\"\\n\", responses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hard Cortex summarization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy.enterSubContext(True)\n",
    "answer = proxy.GenerateAnswer(prompt=\"summarize this conversation in one short sentence\")\n",
    "proxy.exitSubContext()\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cortical Conversation Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy.enterSubContext(deepCopy=True)\n",
    "answer = proxy.GenerateAnswer(prompt=\"What is the main topic of this conversation? Be objective.\")\n",
    "proxy.exitSubContext()\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Relevance by topic***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy.enterSubContext(deepCopy=False)\n",
    "answer = proxy.GenerateAnswer(prompt=f\"\"\"Memory processing is an expensive task and should be reserved for really relevant content and things you don't already know.\n",
    "                              Do you think that a conversation about {answer} is relevant enough to be stored in memory? Or is it something you already know? Be objective. Answer with Yes or No\"\"\")\n",
    "proxy.exitSubContext()\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy.enterSubContext(deepCopy=True)\n",
    "proxy.context.systemMessage = \"\"\n",
    "ctx = proxy.context.get_relevant_context_as_text(prompt=\"\")\n",
    "proxy.exitSubContext()\n",
    "\n",
    "print(ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nexus Summarizer prototype and test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Nexus import globalNexus\n",
    "chunkSize = 512\n",
    "overlap = 64\n",
    "wordList = ctx.split(\" \")\n",
    "print(wordList)\n",
    "print(len(wordList))\n",
    "\n",
    "\n",
    "summary = \"\"\n",
    "for i in range(0, len(wordList), chunkSize):\n",
    "  chunks = []\n",
    "  end = i+chunkSize\n",
    "  if(i>overlap):\n",
    "    chunks.extend(wordList[i-overlap:i-1])\n",
    "  chunks.extend(wordList[i:end])\n",
    "  if(end+overlap < len(wordList)):\n",
    "    chunks.extend(wordList[end+1:end+overlap])\n",
    "  summary+= globalNexus.summarize(\" \".join(chunks))+\"\\n\"\n",
    "  \n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = globalNexus.summarize(ctx)\n",
    "print(summary)\n",
    "ner = globalNexus.getNER(ctx)\n",
    "print(ner)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stasis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
